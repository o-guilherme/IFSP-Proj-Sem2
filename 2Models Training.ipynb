{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c3ea53-2a75-4552-9866-caa192c62786",
   "metadata": {},
   "source": [
    "# Training and comparison\n",
    "\n",
    "Objective: Trainining of multiple models using the data and comparison of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30de7b8c-7198-4347-b6c4-c0f93861f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing most used modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import phik\n",
    "sns.set_palette('viridis')\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score, ConfusionMatrixDisplay\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29ccf1-cc09-4ec0-87ad-57b01dfa19ef",
   "metadata": {},
   "source": [
    "Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf285216-6f3f-4911-b727-6756e34c0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets\n",
    "test_sets = ['numeric','categoricals_binned','one_hot_encoded','outliers_removed',\n",
    "             'one_hot_encoded_rescaled','oversampled+','oversampled-','smoted+','smoted-']\n",
    "datasets = {}\n",
    "for key in test_sets:\n",
    "    datasets[key] = pd.read_csv(f'datasets/{key}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5383a6-62f1-4d98-a4cd-fa01b62a27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the X,y spliter for ease of use\n",
    "def df_splitter(dataset, target = 'Response'):\n",
    "    X = dataset.drop(columns=[target])\n",
    "    y = dataset[target].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a32e0e-3dd0-4cde-b2be-78ce6d94e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the printing function\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"\\nMean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabe4b6-2471-4eca-9dcf-84cbfbef9c3e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb0cb6-5559-4a9f-a508-b76638bba269",
   "metadata": {},
   "source": [
    "## Dataset tests\n",
    "Since we have some datasets options, we will try a first run of t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8caa259-2e57-4dee-bebb-13f3172b63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105729d-f7fb-4f7b-910d-f3b6b1956e24",
   "metadata": {},
   "source": [
    "#### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1f4ea0-a977-41d0-ac8e-9d5616c0f5fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.71228536 0.71211675 0.71491745]\n",
      "\n",
      "Mean: 0.7131065181467098\n",
      "Standard deviation: 0.0012823729935557734\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.71059032 0.70769458 0.71005307]\n",
      "\n",
      "Mean: 0.7094459858904245\n",
      "Standard deviation: 0.0012577064482832434\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.71022183 0.70850531 0.70953715]\n",
      "\n",
      "Mean: 0.7094214273332063\n",
      "Standard deviation: 0.0007055284432189075\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.71475655 0.70724399 0.71301221]\n",
      "\n",
      "Mean: 0.711670917757777\n",
      "Standard deviation: 0.00321029198290776\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.71464367 0.71395932 0.71587559]\n",
      "\n",
      "Mean: 0.7148261929129059\n",
      "Standard deviation: 0.0007928897487709854\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.62038204 0.6198303  0.6208    ]\n",
      "\n",
      "Mean: 0.620337448371037\n",
      "Standard deviation: 0.0003971309629555497\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.61266322 0.611905   0.6137282 ]\n",
      "\n",
      "Mean: 0.6127654698725807\n",
      "Standard deviation: 0.0007478214047553315\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.62004266 0.61682424 0.61197576]\n",
      "\n",
      "Mean: 0.6162808881993601\n",
      "Standard deviation: 0.0033156369510721063\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.64818921 0.64856608 0.65635163]\n",
      "\n",
      "Mean: 0.6510356396109004\n",
      "Standard deviation: 0.003762120960200458\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5, n_jobs = -1)\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    knn_test = cross_val_score(knn_clf,X_train,y_train, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "    first_results.append({'model':'KNN', 'dataset':key, 'score':knn_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(knn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d451f17-cf9e-45e5-94f5-173b078d90ef",
   "metadata": {},
   "source": [
    "#### Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3392e106-2f19-4f8c-b507-577081322b47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.75592679 0.74695983 0.74462597 0.75113622 0.74695983]\n",
      "\n",
      "Mean: 0.7491217295172583\n",
      "Standard deviation: 0.003998162378626328\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.75690947 0.74953937 0.74376612 0.75224174 0.746837  ]\n",
      "\n",
      "Mean: 0.749858739712566\n",
      "Standard deviation: 0.004510973372125921\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.75506695 0.74941653 0.7443803  0.7492937  0.74867952]\n",
      "\n",
      "Mean: 0.7493673995823609\n",
      "Standard deviation: 0.003401088891060924\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.75418227 0.75156055 0.74956305 0.75402672 0.7445374 ]\n",
      "\n",
      "Mean: 0.7507739966071254\n",
      "Standard deviation: 0.003554625483263591\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.72583221 0.72976293 0.72816607 0.71919912 0.72288417]\n",
      "\n",
      "Mean: 0.725168898169758\n",
      "Standard deviation: 0.003778530191324014\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.52828054 0.53139394 0.53373737 0.52711111 0.52864646]\n",
      "\n",
      "Mean: 0.5298338863750629\n",
      "Standard deviation: 0.0024044679324950508\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.54151269 0.53420383 0.52878377 0.53268725 0.5342477 ]\n",
      "\n",
      "Mean: 0.5342870482870001\n",
      "Standard deviation: 0.0041246509318381575\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.73796057 0.73519192 0.73567677 0.73591919 0.73139394]\n",
      "\n",
      "Mean: 0.735228477404948\n",
      "Standard deviation: 0.0021376338598672697\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.6317648  0.63775971 0.63299663 0.63428055 0.6364159 ]\n",
      "\n",
      "Mean: 0.6346435196920759\n",
      "Standard deviation: 0.002190112981087577\n"
     ]
    }
   ],
   "source": [
    "nbg_clf = GaussianNB()\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    nbg_test = cross_val_score(nbg_clf,X_train,y_train, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "    first_results.append({'model':'Naive Bayes', 'dataset':key, 'score':nbg_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(nbg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f64f3-3373-4614-a658-7fdd3e7345d8",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9dbd73-c0ee-42a5-95d9-b3fbe1743a5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.76037931 0.76036753]\n",
      "\n",
      "Mean: 0.7603734183543323\n",
      "Standard deviation: 5.88690779129708e-06\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.76037931 0.76036753]\n",
      "\n",
      "Mean: 0.7603734183543323\n",
      "Standard deviation: 5.88690779129708e-06\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.76037931 0.76036753]\n",
      "\n",
      "Mean: 0.7603734183543323\n",
      "Standard deviation: 5.88690779129708e-06\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.76038753 0.76038753]\n",
      "\n",
      "Mean: 0.7603875349580503\n",
      "Standard deviation: 0.0\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.76037931 0.76036753]\n",
      "\n",
      "Mean: 0.7603734183543323\n",
      "Standard deviation: 5.88690779129708e-06\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.5166462  0.53096516]\n",
      "\n",
      "Mean: 0.5238056758678648\n",
      "Standard deviation: 0.007159480250824246\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.50775245 0.50517394]\n",
      "\n",
      "Mean: 0.5064631951570698\n",
      "Standard deviation: 0.0012892521197188644\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.67318508 0.66920939]\n",
      "\n",
      "Mean: 0.6711972331760294\n",
      "Standard deviation: 0.001987846661064052\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.50463176 0.50550245]\n",
      "\n",
      "Mean: 0.5050671030557676\n",
      "Standard deviation: 0.00043534430141511926\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state = 1216, C = 1.0, cache_size = 4096)\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    svc_test = cross_val_score(svm,X_train,y_train, n_jobs=-1, cv=2, scoring='accuracy')\n",
    "    first_results.append({'model':'Support Vector Machine', 'dataset':key, 'score':svc_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(svc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b5c68-58f6-4a81-bfbc-1b556c9e4188",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04bd7405-1a6e-4ab3-99f7-6c8e3a97d46b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.66195003 0.66384139 0.66376769]\n",
      "\n",
      "Mean: 0.6631863711175029\n",
      "Standard deviation: 0.0008747406010030579\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.63026015 0.63509729 0.63760318]\n",
      "\n",
      "Mean: 0.6343202078382513\n",
      "Standard deviation: 0.003047722663274115\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.64713686 0.64725825 0.64954304]\n",
      "\n",
      "Mean: 0.6479793844129307\n",
      "Standard deviation: 0.0011067834046584052\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.64539326 0.64281969 0.6404225 ]\n",
      "\n",
      "Mean: 0.6428784829510718\n",
      "Standard deviation: 0.002029728015538005\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.64706316 0.64718455 0.64946934]\n",
      "\n",
      "Mean: 0.647905683393311\n",
      "Standard deviation: 0.0011067820263821067\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.77557452 0.77260606 0.7785697 ]\n",
      "\n",
      "Mean: 0.7755834250583015\n",
      "Standard deviation: 0.0024346524976599873\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.7694506  0.77303637 0.77313492]\n",
      "\n",
      "Mean: 0.7718739619164352\n",
      "Standard deviation: 0.00171404536073089\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.69097256 0.69013333 0.69420606]\n",
      "\n",
      "Mean: 0.691770650948543\n",
      "Standard deviation: 0.0017558454830462057\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.74013304 0.73519267 0.74031734]\n",
      "\n",
      "Mean: 0.7385476802168508\n",
      "Standard deviation: 0.0023735448469508185\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=1216)\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    dtc_test = cross_val_score(dtc,X_train,y_train, n_jobs=-1, cv=3, scoring='accuracy') #Default cv value = 5\n",
    "    first_results.append({'model':'Decision Tree', 'dataset':key, 'score':dtc_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(dtc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb704371-82d7-4548-b84e-0a7c93b06cc0",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e02da50-1dad-4d43-8701-447ef90ee2dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.74839708 0.74985259 0.75081073]\n",
      "\n",
      "Mean: 0.7496868023515727\n",
      "Standard deviation: 0.0009923175815198183\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.73793205 0.73776533 0.73540684]\n",
      "\n",
      "Mean: 0.7370347402699734\n",
      "Standard deviation: 0.0011531100974619445\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.71648611 0.72435142 0.72199292]\n",
      "\n",
      "Mean: 0.7209434825543427\n",
      "Standard deviation: 0.0032956294397047925\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.71857678 0.72222638 0.71848079]\n",
      "\n",
      "Mean: 0.7197613160341841\n",
      "Standard deviation: 0.0017435067655318006\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.71648611 0.72435142 0.72199292]\n",
      "\n",
      "Mean: 0.7209434825543427\n",
      "Standard deviation: 0.0032956294397047925\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.83142636 0.83515152 0.83369697]\n",
      "\n",
      "Mean: 0.8334249466447662\n",
      "Standard deviation: 0.0015329061255170064\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.83439271 0.82925988 0.83753819]\n",
      "\n",
      "Mean: 0.8337302586526795\n",
      "Standard deviation: 0.003411913276928968\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.76078736 0.75830303 0.75646061]\n",
      "\n",
      "Mean: 0.7585169973760685\n",
      "Standard deviation: 0.0017728559222234788\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.78980044 0.78303932 0.7873263 ]\n",
      "\n",
      "Mean: 0.7867220229223176\n",
      "Standard deviation: 0.002793093514993346\n"
     ]
    }
   ],
   "source": [
    "extrees = ExtraTreesClassifier(n_jobs=-1, random_state=1216)\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    extrees_test = cross_val_score(extrees,X_train,y_train, n_jobs=-1, cv=3, scoring='accuracy') #Default cv value = 5\n",
    "    first_results.append({'model':'Extra Trees', 'dataset':key, 'score':extrees_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(extrees_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df362ec-b9b1-4b13-ae3f-2dfea8556500",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5540601-92b5-46b7-9a25-6a6b75869ae4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.75488245 0.75670696 0.7550855 ]\n",
      "\n",
      "Mean: 0.7555583018265367\n",
      "Standard deviation: 0.0008164410781646076\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.7478812  0.7499263  0.74985259]\n",
      "\n",
      "Mean: 0.7492200304343605\n",
      "Standard deviation: 0.0009471742677313469\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.74471221 0.75051592 0.75014741]\n",
      "\n",
      "Mean: 0.7484585123768754\n",
      "Standard deviation: 0.002653303283560516\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.74883895 0.75016855 0.75031838]\n",
      "\n",
      "Mean: 0.7497752930568754\n",
      "Standard deviation: 0.0006649128782569847\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.74478591 0.75051592 0.7500737 ]\n",
      "\n",
      "Mean: 0.7484585105663065\n",
      "Standard deviation: 0.002603189114267456\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.82846892 0.83612121 0.8326303 ]\n",
      "\n",
      "Mean: 0.8324068126234713\n",
      "Standard deviation: 0.003128028585296697\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.83178123 0.82743668 0.82970336]\n",
      "\n",
      "Mean: 0.8296404227649076\n",
      "Standard deviation: 0.0017742117696808272\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.7717444  0.77144242 0.76901818]\n",
      "\n",
      "Mean: 0.7707350021107028\n",
      "Standard deviation: 0.0012202189197415957\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.80881991 0.80314379 0.80467133]\n",
      "\n",
      "Mean: 0.8055450080498936\n",
      "Standard deviation: 0.0023982031894877556\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=70,\n",
    "                                 max_leaf_nodes=None,\n",
    "                                 bootstrap=True,\n",
    "                                 oob_score=True,n_jobs = -1,\n",
    "                                 random_state = 1216)\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    rnd_clf_test = cross_val_score(rnd_clf,X_train,y_train, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "    first_results.append({'model':'Random Forest', 'dataset':key, 'score':rnd_clf_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(rnd_clf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe875d-9724-4124-8687-0b7cf66bb5d4",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24c60d86-9139-45da-8ac4-2518a7efb891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Dataset: numeric\n",
      "Scores: [0.75945169 0.75980248 0.75906545]\n",
      "\n",
      "Mean: 0.7594398719611991\n",
      "Standard deviation: 0.0003010065924008337\n",
      "\n",
      "-----\n",
      "Dataset: categoricals_binned\n",
      "Scores: [0.75996757 0.75980248 0.75994988]\n",
      "\n",
      "Mean: 0.7599066438784113\n",
      "Standard deviation: 7.401075954548328e-05\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded\n",
      "Scores: [0.75989388 0.75980248 0.75987618]\n",
      "\n",
      "Mean: 0.7598575104688545\n",
      "Standard deviation: 3.957989254669246e-05\n",
      "\n",
      "-----\n",
      "Dataset: outliers_removed\n",
      "Scores: [0.76022472 0.76028167 0.76020676]\n",
      "\n",
      "Mean: 0.760237715066819\n",
      "Standard deviation: 3.193349830681007e-05\n",
      "\n",
      "-----\n",
      "Dataset: one_hot_encoded_rescaled\n",
      "Scores: [0.75989388 0.75980248 0.75994988]\n",
      "\n",
      "Mean: 0.7598820780789174\n",
      "Standard deviation: 6.0753578180248605e-05\n",
      "\n",
      "-----\n",
      "Dataset: oversampled+\n",
      "Scores: [0.56530592 0.56213333 0.55873939]\n",
      "\n",
      "Mean: 0.5620595506113203\n",
      "Standard deviation: 0.0026812825313568974\n",
      "\n",
      "-----\n",
      "Dataset: oversampled-\n",
      "Scores: [0.56132052 0.55627279 0.55533655]\n",
      "\n",
      "Mean: 0.5576432883196627\n",
      "Standard deviation: 0.0026281390582369975\n",
      "\n",
      "-----\n",
      "Dataset: smoted+\n",
      "Scores: [0.75787841 0.75510303 0.75471515]\n",
      "\n",
      "Mean: 0.7558988625712179\n",
      "Standard deviation: 0.0014086769958534674\n",
      "\n",
      "-----\n",
      "Dataset: smoted-\n",
      "Scores: [0.81842818 0.81630038 0.81905982]\n",
      "\n",
      "Mean: 0.8179294630895129\n",
      "Standard deviation: 0.0011804418030813039\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier(n_estimators = 500, learning_rate = 0.8, random_state = 1216)\n",
    "for key in test_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)\n",
    "    ada_boost_test = cross_val_score(ada_boost,X_train,y_train, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "    first_results.append({'model':'AdaBoost', 'dataset':key, 'score':ada_boost_test.mean()})\n",
    "    print(f'\\n-----\\nDataset: {key}')\n",
    "    display_scores(ada_boost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87c7ac-c4cc-4b77-ad3f-218459c495d9",
   "metadata": {},
   "source": [
    "#### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa4a6172-2602-4c46-8254-3daa33f3def0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3bbe6_row0_col0 {\n",
       "  background-color: #fff8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col1, #T_3bbe6_row0_col3 {\n",
       "  background-color: #f6f6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col2 {\n",
       "  background-color: #fffefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col4 {\n",
       "  background-color: #f8f8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col5 {\n",
       "  background-color: #ffcece;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col6 {\n",
       "  background-color: #ffd0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col7, #T_3bbe6_row2_col5, #T_3bbe6_row2_col6, #T_3bbe6_row2_col8, #T_3bbe6_row3_col0, #T_3bbe6_row3_col1, #T_3bbe6_row3_col2, #T_3bbe6_row3_col3, #T_3bbe6_row3_col4 {\n",
       "  background-color: #ff8e8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row0_col8 {\n",
       "  background-color: #ffeeee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col0, #T_3bbe6_row4_col0 {\n",
       "  background-color: #babaff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col1, #T_3bbe6_row1_col4, #T_3bbe6_row4_col7, #T_3bbe6_row5_col1 {\n",
       "  background-color: #b4b4ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col2, #T_3bbe6_row5_col4, #T_3bbe6_row6_col7 {\n",
       "  background-color: #b6b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col3 {\n",
       "  background-color: #e2e2ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col5 {\n",
       "  background-color: #ff9292;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col6 {\n",
       "  background-color: #ffa0a0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col7 {\n",
       "  background-color: #d2d2ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row1_col8 {\n",
       "  background-color: #ffe4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row2_col0, #T_3bbe6_row2_col1, #T_3bbe6_row2_col2, #T_3bbe6_row2_col3, #T_3bbe6_row2_col4, #T_3bbe6_row4_col5, #T_3bbe6_row4_col6, #T_3bbe6_row5_col7, #T_3bbe6_row6_col8 {\n",
       "  background-color: #a2a2ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bbe6_row2_col7 {\n",
       "  background-color: #ffd8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row3_col5, #T_3bbe6_row3_col6 {\n",
       "  background-color: #cacaff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row3_col7 {\n",
       "  background-color: #fff2f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row3_col8 {\n",
       "  background-color: #d6d6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row4_col1 {\n",
       "  background-color: #c8c8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row4_col2, #T_3bbe6_row4_col3, #T_3bbe6_row4_col4 {\n",
       "  background-color: #eaeaff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row4_col8, #T_3bbe6_row5_col2, #T_3bbe6_row5_col3 {\n",
       "  background-color: #b8b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row5_col0 {\n",
       "  background-color: #acacff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row5_col5, #T_3bbe6_row6_col0, #T_3bbe6_row6_col1, #T_3bbe6_row6_col2, #T_3bbe6_row6_col3, #T_3bbe6_row6_col4 {\n",
       "  background-color: #a4a4ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row5_col6 {\n",
       "  background-color: #a6a6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row5_col8 {\n",
       "  background-color: #aaaaff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row6_col5 {\n",
       "  background-color: #ffa8a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bbe6_row6_col6 {\n",
       "  background-color: #ffaeae;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3bbe6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >dataset</th>\n",
       "      <th id=\"T_3bbe6_level0_col0\" class=\"col_heading level0 col0\" >numeric</th>\n",
       "      <th id=\"T_3bbe6_level0_col1\" class=\"col_heading level0 col1\" >categoricals_binned</th>\n",
       "      <th id=\"T_3bbe6_level0_col2\" class=\"col_heading level0 col2\" >one_hot_encoded</th>\n",
       "      <th id=\"T_3bbe6_level0_col3\" class=\"col_heading level0 col3\" >one_hot_encoded_rescaled</th>\n",
       "      <th id=\"T_3bbe6_level0_col4\" class=\"col_heading level0 col4\" >outliers_removed</th>\n",
       "      <th id=\"T_3bbe6_level0_col5\" class=\"col_heading level0 col5\" >oversampled+</th>\n",
       "      <th id=\"T_3bbe6_level0_col6\" class=\"col_heading level0 col6\" >oversampled-</th>\n",
       "      <th id=\"T_3bbe6_level0_col7\" class=\"col_heading level0 col7\" >smoted+</th>\n",
       "      <th id=\"T_3bbe6_level0_col8\" class=\"col_heading level0 col8\" >smoted-</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row0\" class=\"row_heading level0 row0\" >KNN</th>\n",
       "      <td id=\"T_3bbe6_row0_col0\" class=\"data row0 col0\" >0.713107</td>\n",
       "      <td id=\"T_3bbe6_row0_col1\" class=\"data row0 col1\" >0.709446</td>\n",
       "      <td id=\"T_3bbe6_row0_col2\" class=\"data row0 col2\" >0.709421</td>\n",
       "      <td id=\"T_3bbe6_row0_col3\" class=\"data row0 col3\" >0.714826</td>\n",
       "      <td id=\"T_3bbe6_row0_col4\" class=\"data row0 col4\" >0.711671</td>\n",
       "      <td id=\"T_3bbe6_row0_col5\" class=\"data row0 col5\" >0.620337</td>\n",
       "      <td id=\"T_3bbe6_row0_col6\" class=\"data row0 col6\" >0.612765</td>\n",
       "      <td id=\"T_3bbe6_row0_col7\" class=\"data row0 col7\" >0.616281</td>\n",
       "      <td id=\"T_3bbe6_row0_col8\" class=\"data row0 col8\" >0.651036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row1\" class=\"row_heading level0 row1\" >Naive Bayes</th>\n",
       "      <td id=\"T_3bbe6_row1_col0\" class=\"data row1 col0\" >0.749122</td>\n",
       "      <td id=\"T_3bbe6_row1_col1\" class=\"data row1 col1\" >0.749859</td>\n",
       "      <td id=\"T_3bbe6_row1_col2\" class=\"data row1 col2\" >0.749367</td>\n",
       "      <td id=\"T_3bbe6_row1_col3\" class=\"data row1 col3\" >0.725169</td>\n",
       "      <td id=\"T_3bbe6_row1_col4\" class=\"data row1 col4\" >0.750774</td>\n",
       "      <td id=\"T_3bbe6_row1_col5\" class=\"data row1 col5\" >0.529834</td>\n",
       "      <td id=\"T_3bbe6_row1_col6\" class=\"data row1 col6\" >0.534287</td>\n",
       "      <td id=\"T_3bbe6_row1_col7\" class=\"data row1 col7\" >0.735228</td>\n",
       "      <td id=\"T_3bbe6_row1_col8\" class=\"data row1 col8\" >0.634644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_3bbe6_row2_col0\" class=\"data row2 col0\" >0.760373</td>\n",
       "      <td id=\"T_3bbe6_row2_col1\" class=\"data row2 col1\" >0.760373</td>\n",
       "      <td id=\"T_3bbe6_row2_col2\" class=\"data row2 col2\" >0.760373</td>\n",
       "      <td id=\"T_3bbe6_row2_col3\" class=\"data row2 col3\" >0.760373</td>\n",
       "      <td id=\"T_3bbe6_row2_col4\" class=\"data row2 col4\" >0.760388</td>\n",
       "      <td id=\"T_3bbe6_row2_col5\" class=\"data row2 col5\" >0.523806</td>\n",
       "      <td id=\"T_3bbe6_row2_col6\" class=\"data row2 col6\" >0.506463</td>\n",
       "      <td id=\"T_3bbe6_row2_col7\" class=\"data row2 col7\" >0.671197</td>\n",
       "      <td id=\"T_3bbe6_row2_col8\" class=\"data row2 col8\" >0.505067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row3\" class=\"row_heading level0 row3\" >Decision Tree</th>\n",
       "      <td id=\"T_3bbe6_row3_col0\" class=\"data row3 col0\" >0.663186</td>\n",
       "      <td id=\"T_3bbe6_row3_col1\" class=\"data row3 col1\" >0.634320</td>\n",
       "      <td id=\"T_3bbe6_row3_col2\" class=\"data row3 col2\" >0.647979</td>\n",
       "      <td id=\"T_3bbe6_row3_col3\" class=\"data row3 col3\" >0.647906</td>\n",
       "      <td id=\"T_3bbe6_row3_col4\" class=\"data row3 col4\" >0.642878</td>\n",
       "      <td id=\"T_3bbe6_row3_col5\" class=\"data row3 col5\" >0.775583</td>\n",
       "      <td id=\"T_3bbe6_row3_col6\" class=\"data row3 col6\" >0.771874</td>\n",
       "      <td id=\"T_3bbe6_row3_col7\" class=\"data row3 col7\" >0.691771</td>\n",
       "      <td id=\"T_3bbe6_row3_col8\" class=\"data row3 col8\" >0.738548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row4\" class=\"row_heading level0 row4\" >Extra Trees</th>\n",
       "      <td id=\"T_3bbe6_row4_col0\" class=\"data row4 col0\" >0.749687</td>\n",
       "      <td id=\"T_3bbe6_row4_col1\" class=\"data row4 col1\" >0.737035</td>\n",
       "      <td id=\"T_3bbe6_row4_col2\" class=\"data row4 col2\" >0.720943</td>\n",
       "      <td id=\"T_3bbe6_row4_col3\" class=\"data row4 col3\" >0.720943</td>\n",
       "      <td id=\"T_3bbe6_row4_col4\" class=\"data row4 col4\" >0.719761</td>\n",
       "      <td id=\"T_3bbe6_row4_col5\" class=\"data row4 col5\" >0.833425</td>\n",
       "      <td id=\"T_3bbe6_row4_col6\" class=\"data row4 col6\" >0.833730</td>\n",
       "      <td id=\"T_3bbe6_row4_col7\" class=\"data row4 col7\" >0.758517</td>\n",
       "      <td id=\"T_3bbe6_row4_col8\" class=\"data row4 col8\" >0.786722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row5\" class=\"row_heading level0 row5\" >Random Forest</th>\n",
       "      <td id=\"T_3bbe6_row5_col0\" class=\"data row5 col0\" >0.755558</td>\n",
       "      <td id=\"T_3bbe6_row5_col1\" class=\"data row5 col1\" >0.749220</td>\n",
       "      <td id=\"T_3bbe6_row5_col2\" class=\"data row5 col2\" >0.748459</td>\n",
       "      <td id=\"T_3bbe6_row5_col3\" class=\"data row5 col3\" >0.748459</td>\n",
       "      <td id=\"T_3bbe6_row5_col4\" class=\"data row5 col4\" >0.749775</td>\n",
       "      <td id=\"T_3bbe6_row5_col5\" class=\"data row5 col5\" >0.832407</td>\n",
       "      <td id=\"T_3bbe6_row5_col6\" class=\"data row5 col6\" >0.829640</td>\n",
       "      <td id=\"T_3bbe6_row5_col7\" class=\"data row5 col7\" >0.770735</td>\n",
       "      <td id=\"T_3bbe6_row5_col8\" class=\"data row5 col8\" >0.805545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bbe6_level0_row6\" class=\"row_heading level0 row6\" >AdaBoost</th>\n",
       "      <td id=\"T_3bbe6_row6_col0\" class=\"data row6 col0\" >0.759440</td>\n",
       "      <td id=\"T_3bbe6_row6_col1\" class=\"data row6 col1\" >0.759907</td>\n",
       "      <td id=\"T_3bbe6_row6_col2\" class=\"data row6 col2\" >0.759858</td>\n",
       "      <td id=\"T_3bbe6_row6_col3\" class=\"data row6 col3\" >0.759882</td>\n",
       "      <td id=\"T_3bbe6_row6_col4\" class=\"data row6 col4\" >0.760238</td>\n",
       "      <td id=\"T_3bbe6_row6_col5\" class=\"data row6 col5\" >0.562060</td>\n",
       "      <td id=\"T_3bbe6_row6_col6\" class=\"data row6 col6\" >0.557643</td>\n",
       "      <td id=\"T_3bbe6_row6_col7\" class=\"data row6 col7\" >0.755899</td>\n",
       "      <td id=\"T_3bbe6_row6_col8\" class=\"data row6 col8\" >0.817929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14affc9b910>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = first_results\n",
    "results = pd.DataFrame(results)\n",
    "results = results.pivot(index='model', columns = 'dataset', values = 'score')\n",
    "results = results.reindex(columns= [ 'numeric','categoricals_binned','one_hot_encoded','one_hot_encoded_rescaled','outliers_removed','oversampled+','oversampled-','smoted+','smoted-'])\n",
    "results = results.reindex(['KNN', 'Naive Bayes', 'Support Vector Machine', 'Decision Tree', 'Extra Trees', 'Random Forest', 'AdaBoost'])\n",
    "results.style.background_gradient(cmap='bwr_r', low=0.7, high=0.8, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0643103-83d8-4496-b6d7-c649deb4a5b3",
   "metadata": {},
   "source": [
    "### Improving the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bb508-55e8-476f-9a3c-92abbcba02eb",
   "metadata": {},
   "source": [
    "Reanalizing the best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeaad9a-cb41-46c0-a699-cec67e211acf",
   "metadata": {},
   "source": [
    "#### Extra Trees\n",
    "'oversampled-' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d6c16a-9dc5-4ffd-b824-ebc964762929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the classifier\n",
    "extra_tree = ExtraTreesClassifier(n_estimators=1000, random_state=1216, n_jobs = -1)\n",
    "X, y = df_splitter(datasets['oversampled-'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f04e58-5166-41fa-992b-6194d9ffb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the parameters for the grid search\n",
    "min_samples_split = np.array([2,10,40])\n",
    "max_depth = np.array([10,50,100,None])\n",
    "max_leaf_nodes = np.array([5,20,None])\n",
    "values_grid = {'min_samples_split': min_samples_split,\n",
    "               'max_depth': max_depth,\n",
    "               'max_leaf_nodes':max_leaf_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a7d81c-dbd0-4255-b3d4-6a80ea644c34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=5, min_samples_split=2;, score=0.568 total time=   4.5s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=5, min_samples_split=2;, score=0.559 total time=   3.6s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=5, min_samples_split=10;, score=0.568 total time=   3.3s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=5, min_samples_split=10;, score=0.559 total time=   3.0s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=5, min_samples_split=40;, score=0.568 total time=   3.4s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=5, min_samples_split=40;, score=0.559 total time=   2.9s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=20, min_samples_split=2;, score=0.579 total time=   4.0s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=20, min_samples_split=2;, score=0.573 total time=   3.7s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=20, min_samples_split=10;, score=0.579 total time=   4.0s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=20, min_samples_split=10;, score=0.574 total time=   4.1s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=20, min_samples_split=40;, score=0.580 total time=   4.0s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=20, min_samples_split=40;, score=0.572 total time=   3.9s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=None, min_samples_split=2;, score=0.619 total time=   6.9s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=None, min_samples_split=2;, score=0.609 total time=   7.7s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=None, min_samples_split=10;, score=0.610 total time=   6.9s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=None, min_samples_split=10;, score=0.601 total time=   6.9s\n",
      "[CV 1/2] END max_depth=10, max_leaf_nodes=None, min_samples_split=40;, score=0.600 total time=   7.1s\n",
      "[CV 2/2] END max_depth=10, max_leaf_nodes=None, min_samples_split=40;, score=0.593 total time=   6.5s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=2;, score=0.568 total time=   3.2s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=2;, score=0.559 total time=   2.9s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=10;, score=0.568 total time=   3.1s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=10;, score=0.559 total time=   3.0s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=40;, score=0.568 total time=   3.1s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=40;, score=0.559 total time=   3.1s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=2;, score=0.580 total time=   4.2s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=2;, score=0.573 total time=   3.8s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=10;, score=0.580 total time=   4.2s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=10;, score=0.573 total time=   3.8s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=40;, score=0.580 total time=   4.2s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=40;, score=0.573 total time=   4.1s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=2;, score=0.779 total time=  23.4s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=2;, score=0.778 total time=  24.7s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=10;, score=0.734 total time=  17.2s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=10;, score=0.739 total time=  17.5s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=40;, score=0.672 total time=  12.9s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=40;, score=0.675 total time=  13.1s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=5, min_samples_split=2;, score=0.568 total time=   3.2s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=5, min_samples_split=2;, score=0.559 total time=   3.3s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=5, min_samples_split=10;, score=0.568 total time=   3.2s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=5, min_samples_split=10;, score=0.559 total time=   2.8s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=5, min_samples_split=40;, score=0.568 total time=   3.3s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=5, min_samples_split=40;, score=0.559 total time=   2.9s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=20, min_samples_split=2;, score=0.580 total time=   4.2s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=20, min_samples_split=2;, score=0.573 total time=   4.0s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=20, min_samples_split=10;, score=0.580 total time=   4.2s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=20, min_samples_split=10;, score=0.573 total time=   3.8s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=20, min_samples_split=40;, score=0.580 total time=   4.2s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=20, min_samples_split=40;, score=0.573 total time=   3.7s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=None, min_samples_split=2;, score=0.779 total time=  23.5s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=None, min_samples_split=2;, score=0.778 total time=  24.4s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=None, min_samples_split=10;, score=0.734 total time=  16.5s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=None, min_samples_split=10;, score=0.739 total time=  16.9s\n",
      "[CV 1/2] END max_depth=100, max_leaf_nodes=None, min_samples_split=40;, score=0.672 total time=  12.9s\n",
      "[CV 2/2] END max_depth=100, max_leaf_nodes=None, min_samples_split=40;, score=0.675 total time=  12.5s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=5, min_samples_split=2;, score=0.568 total time=   3.2s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=5, min_samples_split=2;, score=0.559 total time=   3.0s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=5, min_samples_split=10;, score=0.568 total time=   3.6s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=5, min_samples_split=10;, score=0.559 total time=   3.1s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=5, min_samples_split=40;, score=0.568 total time=   3.4s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=5, min_samples_split=40;, score=0.559 total time=   3.2s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=20, min_samples_split=2;, score=0.580 total time=   4.6s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=20, min_samples_split=2;, score=0.573 total time=   3.8s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=20, min_samples_split=10;, score=0.580 total time=   4.1s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=20, min_samples_split=10;, score=0.573 total time=   3.8s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=20, min_samples_split=40;, score=0.580 total time=   3.9s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=20, min_samples_split=40;, score=0.573 total time=   3.9s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=None, min_samples_split=2;, score=0.779 total time=  25.0s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=None, min_samples_split=2;, score=0.778 total time=  22.6s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=None, min_samples_split=10;, score=0.734 total time=  16.1s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=None, min_samples_split=10;, score=0.739 total time=  17.9s\n",
      "[CV 1/2] END max_depth=None, max_leaf_nodes=None, min_samples_split=40;, score=0.672 total time=  13.0s\n",
      "[CV 2/2] END max_depth=None, max_leaf_nodes=None, min_samples_split=40;, score=0.675 total time=  12.6s\n"
     ]
    }
   ],
   "source": [
    "#Using grid search to find the best values\n",
    "gridExtraTrees = GridSearchCV(estimator = extra_tree,\n",
    "                                param_grid = values_grid,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1)\n",
    "gridExtraTrees.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2373c1-800f-4272-98bb-28a95b46a9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.261000</td>\n",
       "      <td>0.611980</td>\n",
       "      <td>2.901989</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.778990</td>\n",
       "      <td>0.777570</td>\n",
       "      <td>0.778280</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21.153958</td>\n",
       "      <td>0.468042</td>\n",
       "      <td>2.908001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': None, 'mi...</td>\n",
       "      <td>0.778563</td>\n",
       "      <td>0.777898</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20.466670</td>\n",
       "      <td>0.584650</td>\n",
       "      <td>3.444990</td>\n",
       "      <td>0.619011</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': None, 'm...</td>\n",
       "      <td>0.778563</td>\n",
       "      <td>0.777898</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.966989</td>\n",
       "      <td>0.052010</td>\n",
       "      <td>2.475501</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.734380</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.736692</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14.525990</td>\n",
       "      <td>0.772012</td>\n",
       "      <td>2.592503</td>\n",
       "      <td>0.109498</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': None, 'm...</td>\n",
       "      <td>0.734183</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.736593</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.335109</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>2.434500</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': None, 'mi...</td>\n",
       "      <td>0.734183</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.736593</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.837001</td>\n",
       "      <td>0.147001</td>\n",
       "      <td>2.001499</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': None, 'mi...</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.674978</td>\n",
       "      <td>0.673456</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.005521</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>2.078479</td>\n",
       "      <td>0.011498</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.674978</td>\n",
       "      <td>0.673456</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.879758</td>\n",
       "      <td>0.112759</td>\n",
       "      <td>2.002000</td>\n",
       "      <td>0.079001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': None, 'm...</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.674978</td>\n",
       "      <td>0.673456</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.085502</td>\n",
       "      <td>0.298501</td>\n",
       "      <td>1.311499</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.618586</td>\n",
       "      <td>0.609178</td>\n",
       "      <td>0.613882</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.673536</td>\n",
       "      <td>0.049535</td>\n",
       "      <td>1.306070</td>\n",
       "      <td>0.077931</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.610177</td>\n",
       "      <td>0.600900</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.654065</td>\n",
       "      <td>0.381953</td>\n",
       "      <td>1.244238</td>\n",
       "      <td>0.104259</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.600158</td>\n",
       "      <td>0.593049</td>\n",
       "      <td>0.596603</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.371116</td>\n",
       "      <td>0.146117</td>\n",
       "      <td>0.679246</td>\n",
       "      <td>0.027245</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 20, 'min...</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.572977</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.446121</td>\n",
       "      <td>0.208421</td>\n",
       "      <td>0.697243</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.572977</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.440004</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.660109</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 20, 'min_...</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.572977</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.475011</td>\n",
       "      <td>0.050990</td>\n",
       "      <td>0.664489</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579134</td>\n",
       "      <td>0.573798</td>\n",
       "      <td>0.576466</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.602028</td>\n",
       "      <td>0.366219</td>\n",
       "      <td>0.674468</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 20, 'min...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.445783</td>\n",
       "      <td>0.097021</td>\n",
       "      <td>0.730025</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 20, 'min_...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.463846</td>\n",
       "      <td>0.194431</td>\n",
       "      <td>0.638175</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.312007</td>\n",
       "      <td>0.120005</td>\n",
       "      <td>0.628493</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579463</td>\n",
       "      <td>0.573404</td>\n",
       "      <td>0.576433</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.350415</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.650252</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 20, 'min...</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.572846</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.505544</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.752870</td>\n",
       "      <td>0.053870</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.572846</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.435702</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.637618</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 20, 'min_...</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.572846</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.385000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579725</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.575974</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.536199</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.649443</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 5, 'min_...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.487999</td>\n",
       "      <td>0.455999</td>\n",
       "      <td>0.653499</td>\n",
       "      <td>0.020501</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.596447</td>\n",
       "      <td>0.154914</td>\n",
       "      <td>0.572825</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.772165</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.622953</td>\n",
       "      <td>0.065044</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.624749</td>\n",
       "      <td>0.188737</td>\n",
       "      <td>0.585756</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.816191</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.569016</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 5, 'min_...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.558001</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.658500</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.699506</td>\n",
       "      <td>0.204493</td>\n",
       "      <td>0.551993</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.533079</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.543378</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.849511</td>\n",
       "      <td>0.272511</td>\n",
       "      <td>0.605489</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 5, 'min_...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.747000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.597286</td>\n",
       "      <td>0.085080</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15      21.261000      0.611980         2.901989        0.047012   \n",
       "24      21.153958      0.468042         2.908001        0.050001   \n",
       "33      20.466670      0.584650         3.444990        0.619011   \n",
       "16      14.966989      0.052010         2.475501        0.057500   \n",
       "34      14.525990      0.772012         2.592503        0.109498   \n",
       "25      14.335109      0.219109         2.434500        0.032501   \n",
       "26      10.837001      0.147001         2.001499        0.050500   \n",
       "17      11.005521      0.062502         2.078479        0.011498   \n",
       "35      10.879758      0.112759         2.002000        0.079001   \n",
       "6        6.085502      0.298501         1.311499        0.128500   \n",
       "7        5.673536      0.049535         1.306070        0.077931   \n",
       "8        5.654065      0.381953         1.244238        0.104259   \n",
       "31       3.371116      0.146117         0.679246        0.027245   \n",
       "13       3.446121      0.208421         0.697243        0.003740   \n",
       "22       3.440004      0.179110         0.660109        0.017040   \n",
       "4        3.475011      0.050990         0.664489        0.033491   \n",
       "30       3.602028      0.366219         0.674468        0.010533   \n",
       "21       3.445783      0.097021         0.730025        0.001673   \n",
       "12       3.463846      0.194431         0.638175        0.002005   \n",
       "3        3.312007      0.120005         0.628493        0.004506   \n",
       "32       3.350415      0.026640         0.650252        0.006107   \n",
       "14       3.505544      0.002546         0.752870        0.053870   \n",
       "23       3.435702      0.220300         0.637618        0.007379   \n",
       "5        3.385000      0.067000         0.673000        0.021000   \n",
       "27       2.536199      0.050200         0.649443        0.028443   \n",
       "0        3.487999      0.455999         0.653499        0.020501   \n",
       "9        2.596447      0.154914         0.572825        0.008983   \n",
       "18       2.772165      0.016615         0.622953        0.065044   \n",
       "20       2.624749      0.188737         0.585756        0.002988   \n",
       "29       2.816191      0.114976         0.569016        0.013465   \n",
       "11       2.558001      0.029999         0.658500        0.055500   \n",
       "2        2.699506      0.204493         0.551993        0.034006   \n",
       "19       2.533079      0.185921         0.543378        0.001621   \n",
       "28       2.849511      0.272511         0.605489        0.003489   \n",
       "1        2.747000      0.135000         0.549500        0.013500   \n",
       "10       2.597286      0.085080         0.550992        0.016009   \n",
       "\n",
       "   param_max_depth param_max_leaf_nodes param_min_samples_split  \\\n",
       "15              50                 None                       2   \n",
       "24             100                 None                       2   \n",
       "33            None                 None                       2   \n",
       "16              50                 None                      10   \n",
       "34            None                 None                      10   \n",
       "25             100                 None                      10   \n",
       "26             100                 None                      40   \n",
       "17              50                 None                      40   \n",
       "35            None                 None                      40   \n",
       "6               10                 None                       2   \n",
       "7               10                 None                      10   \n",
       "8               10                 None                      40   \n",
       "31            None                   20                      10   \n",
       "13              50                   20                      10   \n",
       "22             100                   20                      10   \n",
       "4               10                   20                      10   \n",
       "30            None                   20                       2   \n",
       "21             100                   20                       2   \n",
       "12              50                   20                       2   \n",
       "3               10                   20                       2   \n",
       "32            None                   20                      40   \n",
       "14              50                   20                      40   \n",
       "23             100                   20                      40   \n",
       "5               10                   20                      40   \n",
       "27            None                    5                       2   \n",
       "0               10                    5                       2   \n",
       "9               50                    5                       2   \n",
       "18             100                    5                       2   \n",
       "20             100                    5                      40   \n",
       "29            None                    5                      40   \n",
       "11              50                    5                      40   \n",
       "2               10                    5                      40   \n",
       "19             100                    5                      10   \n",
       "28            None                    5                      10   \n",
       "1               10                    5                      10   \n",
       "10              50                    5                      10   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'max_depth': 50, 'max_leaf_nodes': None, 'min...           0.778990   \n",
       "24  {'max_depth': 100, 'max_leaf_nodes': None, 'mi...           0.778563   \n",
       "33  {'max_depth': None, 'max_leaf_nodes': None, 'm...           0.778563   \n",
       "16  {'max_depth': 50, 'max_leaf_nodes': None, 'min...           0.734380   \n",
       "34  {'max_depth': None, 'max_leaf_nodes': None, 'm...           0.734183   \n",
       "25  {'max_depth': 100, 'max_leaf_nodes': None, 'mi...           0.734183   \n",
       "26  {'max_depth': 100, 'max_leaf_nodes': None, 'mi...           0.671934   \n",
       "17  {'max_depth': 50, 'max_leaf_nodes': None, 'min...           0.671934   \n",
       "35  {'max_depth': None, 'max_leaf_nodes': None, 'm...           0.671934   \n",
       "6   {'max_depth': 10, 'max_leaf_nodes': None, 'min...           0.618586   \n",
       "7   {'max_depth': 10, 'max_leaf_nodes': None, 'min...           0.610177   \n",
       "8   {'max_depth': 10, 'max_leaf_nodes': None, 'min...           0.600158   \n",
       "31  {'max_depth': None, 'max_leaf_nodes': 20, 'min...           0.579988   \n",
       "13  {'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...           0.579988   \n",
       "22  {'max_depth': 100, 'max_leaf_nodes': 20, 'min_...           0.579988   \n",
       "4   {'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...           0.579134   \n",
       "30  {'max_depth': None, 'max_leaf_nodes': 20, 'min...           0.579890   \n",
       "21  {'max_depth': 100, 'max_leaf_nodes': 20, 'min_...           0.579890   \n",
       "12  {'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...           0.579890   \n",
       "3   {'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...           0.579463   \n",
       "32  {'max_depth': None, 'max_leaf_nodes': 20, 'min...           0.579528   \n",
       "14  {'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...           0.579528   \n",
       "23  {'max_depth': 100, 'max_leaf_nodes': 20, 'min_...           0.579528   \n",
       "5   {'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...           0.579725   \n",
       "27  {'max_depth': None, 'max_leaf_nodes': 5, 'min_...           0.568261   \n",
       "0   {'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "9   {'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "18  {'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...           0.568261   \n",
       "20  {'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...           0.568130   \n",
       "29  {'max_depth': None, 'max_leaf_nodes': 5, 'min_...           0.568130   \n",
       "11  {'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...           0.568130   \n",
       "2   {'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...           0.568130   \n",
       "19  {'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...           0.568261   \n",
       "28  {'max_depth': None, 'max_leaf_nodes': 5, 'min_...           0.568261   \n",
       "1   {'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "10  {'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.777570         0.778280        0.000710                1  \n",
       "24           0.777898         0.778230        0.000332                2  \n",
       "33           0.777898         0.778230        0.000332                2  \n",
       "16           0.739003         0.736692        0.002312                4  \n",
       "34           0.739003         0.736593        0.002410                5  \n",
       "25           0.739003         0.736593        0.002410                5  \n",
       "26           0.674978         0.673456        0.001522                7  \n",
       "17           0.674978         0.673456        0.001522                7  \n",
       "35           0.674978         0.673456        0.001522                7  \n",
       "6            0.609178         0.613882        0.004704               10  \n",
       "7            0.600900         0.605538        0.004638               11  \n",
       "8            0.593049         0.596603        0.003554               12  \n",
       "31           0.572977         0.576483        0.003505               13  \n",
       "13           0.572977         0.576483        0.003505               13  \n",
       "22           0.572977         0.576483        0.003505               13  \n",
       "4            0.573798         0.576466        0.002668               16  \n",
       "30           0.573010         0.576450        0.003440               17  \n",
       "21           0.573010         0.576450        0.003440               17  \n",
       "12           0.573010         0.576450        0.003440               17  \n",
       "3            0.573404         0.576433        0.003029               20  \n",
       "32           0.572846         0.576187        0.003341               21  \n",
       "14           0.572846         0.576187        0.003341               21  \n",
       "23           0.572846         0.576187        0.003341               21  \n",
       "5            0.572222         0.575974        0.003752               24  \n",
       "27           0.559049         0.563655        0.004606               25  \n",
       "0            0.559049         0.563655        0.004606               25  \n",
       "9            0.559049         0.563655        0.004606               25  \n",
       "18           0.559049         0.563655        0.004606               25  \n",
       "20           0.559016         0.563573        0.004557               29  \n",
       "29           0.559016         0.563573        0.004557               29  \n",
       "11           0.559016         0.563573        0.004557               29  \n",
       "2            0.559016         0.563573        0.004557               29  \n",
       "19           0.558884         0.563573        0.004688               33  \n",
       "28           0.558884         0.563573        0.004688               33  \n",
       "1            0.558884         0.563573        0.004688               33  \n",
       "10           0.558884         0.563573        0.004688               33  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_results = pd.DataFrame(gridExtraTrees.cv_results_)\n",
    "extra_trees_results.sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8d4de-7aa3-4514-a0a5-ea4a270e2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_extra_trees = gridExtraTrees.best_estimator_\n",
    "best_extra_trees.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b778fc7-1f3b-40ed-89a9-395676353cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_xtr = best_extra_trees.predict(X_test)\n",
    "print(classification_report(y_test, teste_xtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ee28e-a01c-4db5-898e-2adcf8ebb5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e602494-14bc-4c01-b772-b56b8cc584b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a415-c42c-4dd2-b8c3-bf549b79741f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385c44e-4a40-4234-bd69-417a83f1641b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266aa29-c9a2-4ccc-8e2b-fd61a1f4081c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "417452b6-f792-480a-8629-eb4a01d72c75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [334]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgridDecisionTree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:786\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    783\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    784\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 786\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[0;32m    789\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:2333\u001b[0m, in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cv, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m   2328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2329\u001b[0m         classifier\n\u001b[0;32m   2330\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2331\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   2332\u001b[0m     ):\n\u001b[1;32m-> 2333\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStratifiedKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2334\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m KFold(cv)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:652\u001b[0m, in \u001b[0;36mStratifiedKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:286\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    283\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_splits)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_splits \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-fold cross-validation requires at least one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m train/test split by setting n_splits=2 or more,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits)\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shuffle, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle must be True or False; got \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shuffle))\n",
      "\u001b[1;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1."
     ]
    }
   ],
   "source": [
    "gridDecisionTree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f010d7-94fd-44d1-a0c8-fff2c0ae170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_results = pd.DataFrame(gridDecisionTree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "cde6bb0d-5d34-41a8-bfcc-15089b22c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_extra_trees = gridDecisionTree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "78dbd641-b57e-430d-b3e1-ff2054b25e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_extra_tres.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc9849-a37c-4e13-abdc-1f0468f6364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_xtr = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "48615ce6-eed0-4f12-866c-0a0f5bd804ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      7581\n",
      "           1       0.88      0.93      0.91      7640\n",
      "\n",
      "    accuracy                           0.90     15221\n",
      "   macro avg       0.91      0.90      0.90     15221\n",
      "weighted avg       0.91      0.90      0.90     15221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c127d-7dd6-436a-916e-96af5c30a128",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1fe2750b-49a9-4c84-a790-734e332cab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the Classifier\n",
    "rand_forest = RandomForestClassifier(criterion='gini',\n",
    "                                 max_leaf_nodes=None,\n",
    "                                 bootstrap=True,\n",
    "                                 oob_score=True,\n",
    "                                 n_jobs = -1)\n",
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "282ea3a7-0381-49ee-b28f-93026a110d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search parameters\n",
    "n_estimators = np.array([1000,2000])\n",
    "max_depth = np.array([50,None])\n",
    "values_grid_forest = {'n_estimators': n_estimators, 'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0c1d7514-288f-422a-b692-45af48e0934e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 1/2] END ...max_depth=50, n_estimators=1000;, score=0.778 total time=  25.7s\n",
      "[CV 2/2] END ...max_depth=50, n_estimators=1000;, score=0.781 total time=  27.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [354]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m gridForest \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m rand_forest,\n\u001b[0;32m      2\u001b[0m                                 param_grid \u001b[38;5;241m=\u001b[39m values_grid_forest,\n\u001b[0;32m      3\u001b[0m                                 cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                 scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                 pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mgridForest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gridForest = GridSearchCV(estimator = rand_forest,\n",
    "                                param_grid = values_grid_forest,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1)\n",
    "gridForest.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9535d032-66ba-4f16-96a4-95fc05e221ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 588 candidates, totalling 1176 fits\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=70;, score=(train=0.537, test=0.529) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=70;, score=(train=0.552, test=0.549) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.551) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.551) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=200;, score=(train=0.541, test=0.534) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=200;, score=(train=0.551, test=0.548) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=500;, score=(train=0.548, test=0.542) total time=   4.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.549) total time=   3.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.550, test=0.549) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.550) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.546, test=0.539) total time=  14.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  15.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=70;, score=(train=0.560, test=0.557) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=70;, score=(train=0.567, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.559, test=0.547) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.559, test=0.555) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=200;, score=(train=0.562, test=0.556) total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=200;, score=(train=0.570, test=0.562) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=500;, score=(train=0.562, test=0.557) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=500;, score=(train=0.571, test=0.562) total time=   4.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.566, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.570, test=0.562) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.564, test=0.559) total time=  16.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.562) total time=  15.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=70;, score=(train=0.562, test=0.558) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=70;, score=(train=0.570, test=0.563) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.562) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.566, test=0.559) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=200;, score=(train=0.566, test=0.561) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=200;, score=(train=0.568, test=0.562) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=500;, score=(train=0.567, test=0.561) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=500;, score=(train=0.573, test=0.564) total time=   4.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.566, test=0.560) total time=  15.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.562) total time=  15.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=70;, score=(train=0.569, test=0.563) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=70;, score=(train=0.570, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.566, test=0.560) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.560) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=200;, score=(train=0.567, test=0.560) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=200;, score=(train=0.571, test=0.564) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=500;, score=(train=0.568, test=0.562) total time=   4.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=500;, score=(train=0.575, test=0.565) total time=   4.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.572, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.565, test=0.557) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.568, test=0.562) total time=  15.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.575, test=0.565) total time=  15.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=70;, score=(train=0.563, test=0.557) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=70;, score=(train=0.570, test=0.560) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.566, test=0.558) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.571, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=200;, score=(train=0.568, test=0.562) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=200;, score=(train=0.572, test=0.563) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=500;, score=(train=0.569, test=0.563) total time=   4.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=500;, score=(train=0.573, test=0.564) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.566, test=0.559) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.571, test=0.559) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.567, test=0.561) total time=  16.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.573, test=0.564) total time=  16.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=70;, score=(train=0.565, test=0.561) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=70;, score=(train=0.564, test=0.557) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.569, test=0.561) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.566, test=0.558) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=200;, score=(train=0.566, test=0.559) total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=200;, score=(train=0.566, test=0.559) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=500;, score=(train=0.570, test=0.561) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=500;, score=(train=0.576, test=0.564) total time=   4.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.567, test=0.557) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.576, test=0.567) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.569, test=0.563) total time=  16.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.573, test=0.565) total time=  16.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=70;, score=(train=0.560, test=0.548) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=70;, score=(train=0.575, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.566, test=0.559) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.568, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=200;, score=(train=0.567, test=0.560) total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=200;, score=(train=0.569, test=0.560) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=500;, score=(train=0.569, test=0.562) total time=   4.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=500;, score=(train=0.571, test=0.563) total time=   4.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.568, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.572, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.569, test=0.562) total time=  16.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=3, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.575, test=0.564) total time=  16.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=70;, score=(train=0.551, test=0.550) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=70;, score=(train=0.554, test=0.551) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.550) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.549) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=200;, score=(train=0.543, test=0.536) total time=   1.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.552) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=500;, score=(train=0.545, test=0.538) total time=   3.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=500;, score=(train=0.551, test=0.545) total time=   3.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.553, test=0.549) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.549, test=0.542) total time=  14.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.548) total time=  14.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=70;, score=(train=0.559, test=0.556) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=70;, score=(train=0.564, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.561, test=0.559) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.569, test=0.562) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=200;, score=(train=0.567, test=0.562) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=200;, score=(train=0.567, test=0.561) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=500;, score=(train=0.564, test=0.561) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=500;, score=(train=0.570, test=0.562) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.567, test=0.565) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.558) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.559) total time=  16.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.571, test=0.563) total time=  16.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=70;, score=(train=0.566, test=0.560) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=70;, score=(train=0.569, test=0.564) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.570, test=0.562) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=200;, score=(train=0.571, test=0.566) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=200;, score=(train=0.572, test=0.565) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=500;, score=(train=0.572, test=0.565) total time=   4.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=500;, score=(train=0.575, test=0.566) total time=   4.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.564) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.575, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.565) total time=  16.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.575, test=0.567) total time=  17.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=70;, score=(train=0.574, test=0.568) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=70;, score=(train=0.575, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.573, test=0.566) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.566) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=200;, score=(train=0.572, test=0.565) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=200;, score=(train=0.578, test=0.566) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=500;, score=(train=0.575, test=0.566) total time=   4.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=500;, score=(train=0.578, test=0.567) total time=   4.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.573, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.568) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.567) total time=  17.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.578, test=0.568) total time=  17.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=70;, score=(train=0.574, test=0.567) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=70;, score=(train=0.574, test=0.565) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.569) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.578, test=0.569) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=200;, score=(train=0.573, test=0.566) total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=200;, score=(train=0.579, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=500;, score=(train=0.576, test=0.568) total time=   4.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=500;, score=(train=0.579, test=0.569) total time=   4.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.566) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.568) total time=  18.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.580, test=0.571) total time=  16.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=70;, score=(train=0.580, test=0.572) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.571) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.573) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=200;, score=(train=0.583, test=0.573) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=200;, score=(train=0.585, test=0.570) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=500;, score=(train=0.582, test=0.571) total time=   4.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=500;, score=(train=0.586, test=0.572) total time=   4.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.572) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.571) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.581, test=0.571) total time=  17.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  17.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=70;, score=(train=0.607, test=0.584) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=70;, score=(train=0.614, test=0.582) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.614, test=0.588) total time=   1.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.610, test=0.583) total time=   1.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=200;, score=(train=0.613, test=0.586) total time=   2.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=200;, score=(train=0.614, test=0.584) total time=   2.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=500;, score=(train=0.613, test=0.586) total time=   5.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=500;, score=(train=0.612, test=0.582) total time=   5.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.607, test=0.587) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.611, test=0.580) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.614, test=0.589) total time=  23.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.614, test=0.583) total time=  21.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=70;, score=(train=0.539, test=0.529) total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=70;, score=(train=0.537, test=0.534) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.541, test=0.531) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.553, test=0.550) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=200;, score=(train=0.553, test=0.550) total time=   1.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=500;, score=(train=0.546, test=0.540) total time=   3.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=500;, score=(train=0.553, test=0.549) total time=   3.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.546, test=0.545) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.548) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.547, test=0.541) total time=  14.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  14.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=70;, score=(train=0.563, test=0.562) total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=70;, score=(train=0.574, test=0.565) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.557, test=0.554) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.559) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=200;, score=(train=0.563, test=0.558) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=200;, score=(train=0.578, test=0.567) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=500;, score=(train=0.563, test=0.558) total time=   4.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=500;, score=(train=0.570, test=0.563) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.563, test=0.555) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.568, test=0.562) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.562, test=0.559) total time=  15.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.562) total time=  16.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=70;, score=(train=0.574, test=0.566) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=70;, score=(train=0.575, test=0.565) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.564) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.569, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=200;, score=(train=0.569, test=0.562) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=200;, score=(train=0.576, test=0.567) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=500;, score=(train=0.571, test=0.564) total time=   4.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=500;, score=(train=0.575, test=0.566) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.564, test=0.558) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.566) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.571, test=0.564) total time=  16.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.573, test=0.565) total time=  16.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=70;, score=(train=0.568, test=0.561) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=70;, score=(train=0.572, test=0.564) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.572, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.579, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=200;, score=(train=0.573, test=0.565) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=200;, score=(train=0.576, test=0.567) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=500;, score=(train=0.572, test=0.565) total time=   4.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=500;, score=(train=0.578, test=0.568) total time=   4.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.569, test=0.564) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.565) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.573, test=0.565) total time=  17.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.578, test=0.569) total time=  16.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=70;, score=(train=0.573, test=0.567) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=70;, score=(train=0.571, test=0.565) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.567, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=200;, score=(train=0.574, test=0.566) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=200;, score=(train=0.579, test=0.570) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=500;, score=(train=0.576, test=0.567) total time=   4.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.568) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.571, test=0.562) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.569) total time=  16.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.581, test=0.571) total time=  17.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.573) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.571) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.572) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.572) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=200;, score=(train=0.582, test=0.570) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=200;, score=(train=0.586, test=0.571) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=500;, score=(train=0.584, test=0.572) total time=   4.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=500;, score=(train=0.587, test=0.574) total time=   4.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.575) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.571) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.583, test=0.573) total time=  18.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  18.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=70;, score=(train=0.654, test=0.606) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=70;, score=(train=0.650, test=0.597) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.658, test=0.606) total time=   1.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.655, test=0.599) total time=   1.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=200;, score=(train=0.664, test=0.610) total time=   2.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=200;, score=(train=0.659, test=0.602) total time=   2.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=500;, score=(train=0.663, test=0.610) total time=   6.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=500;, score=(train=0.655, test=0.601) total time=   6.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.663, test=0.605) total time=   1.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.651, test=0.599) total time=   1.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.662, test=0.610) total time=  23.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.657, test=0.602) total time=  26.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=70;, score=(train=0.538, test=0.528) total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=70;, score=(train=0.556, test=0.552) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.548, test=0.542) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.535, test=0.537) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=200;, score=(train=0.551, test=0.549) total time=   1.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.548) total time=   4.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=500;, score=(train=0.548, test=0.545) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.539, test=0.530) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.549) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.551, test=0.545) total time=  15.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  14.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=70;, score=(train=0.569, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=70;, score=(train=0.567, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.569, test=0.561) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.568, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=200;, score=(train=0.565, test=0.561) total time=   1.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=200;, score=(train=0.571, test=0.565) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=500;, score=(train=0.564, test=0.560) total time=   3.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=500;, score=(train=0.567, test=0.561) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.561) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.559) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.559) total time=  15.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.562) total time=  16.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=70;, score=(train=0.570, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=70;, score=(train=0.573, test=0.563) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.571) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.565) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=200;, score=(train=0.573, test=0.566) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=200;, score=(train=0.574, test=0.567) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=500;, score=(train=0.569, test=0.563) total time=   4.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=500;, score=(train=0.576, test=0.566) total time=   4.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.565, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.565) total time=  17.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.574, test=0.567) total time=  16.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=70;, score=(train=0.572, test=0.565) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=70;, score=(train=0.575, test=0.568) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.568) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.565) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=200;, score=(train=0.571, test=0.566) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=500;, score=(train=0.574, test=0.566) total time=   5.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=500;, score=(train=0.578, test=0.568) total time=   4.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.567) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.565) total time=   1.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.566) total time=  17.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.576, test=0.567) total time=  16.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=70;, score=(train=0.569, test=0.563) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=70;, score=(train=0.577, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.568) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=500;, score=(train=0.575, test=0.566) total time=   4.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=500;, score=(train=0.578, test=0.568) total time=   4.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.573, test=0.566) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.578, test=0.571) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.568) total time=  19.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.579, test=0.569) total time=  20.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=70;, score=(train=0.583, test=0.571) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=70;, score=(train=0.583, test=0.570) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.574) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=200;, score=(train=0.585, test=0.573) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=200;, score=(train=0.587, test=0.573) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.572) total time=   4.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=500;, score=(train=0.586, test=0.572) total time=   4.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.572) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.581, test=0.571) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.583, test=0.571) total time=  18.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  19.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=70;, score=(train=0.856, test=0.684) total time=   1.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=70;, score=(train=0.855, test=0.683) total time=   1.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.866, test=0.689) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.857, test=0.684) total time=   2.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=200;, score=(train=0.863, test=0.690) total time=   3.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=200;, score=(train=0.865, test=0.690) total time=   3.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=500;, score=(train=0.874, test=0.698) total time=   8.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=500;, score=(train=0.865, test=0.690) total time=   8.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.864, test=0.689) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.853, test=0.682) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.874, test=0.696) total time=  37.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.867, test=0.689) total time=  35.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=70;, score=(train=0.539, test=0.532) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=70;, score=(train=0.558, test=0.555) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.542, test=0.533) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.553, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=200;, score=(train=0.540, test=0.532) total time=   1.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.548) total time=   1.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=500;, score=(train=0.545, test=0.539) total time=   3.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=500;, score=(train=0.551, test=0.548) total time=   3.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.546) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.550) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.551, test=0.548) total time=  14.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  15.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=70;, score=(train=0.560, test=0.555) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=70;, score=(train=0.573, test=0.564) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.570, test=0.562) total time=   1.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.567, test=0.560) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=200;, score=(train=0.568, test=0.560) total time=   2.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=200;, score=(train=0.567, test=0.559) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=500;, score=(train=0.563, test=0.559) total time=   4.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=500;, score=(train=0.571, test=0.563) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.559) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.573, test=0.566) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.559) total time=  16.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.563) total time=  15.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=70;, score=(train=0.570, test=0.564) total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=70;, score=(train=0.578, test=0.571) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.570, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=200;, score=(train=0.568, test=0.563) total time=   1.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=200;, score=(train=0.572, test=0.563) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=500;, score=(train=0.571, test=0.564) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.571, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.573, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.571, test=0.564) total time=  15.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.575, test=0.566) total time=  15.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=70;, score=(train=0.570, test=0.561) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=70;, score=(train=0.575, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.577, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=200;, score=(train=0.572, test=0.566) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=200;, score=(train=0.576, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=500;, score=(train=0.575, test=0.567) total time=   4.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=500;, score=(train=0.579, test=0.568) total time=   4.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.568, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.573, test=0.567) total time=  15.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.577, test=0.568) total time=  15.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=70;, score=(train=0.570, test=0.559) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=70;, score=(train=0.578, test=0.564) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.568) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.580, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=200;, score=(train=0.576, test=0.565) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=200;, score=(train=0.579, test=0.566) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=500;, score=(train=0.574, test=0.566) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=500;, score=(train=0.581, test=0.569) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.571, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.577, test=0.569) total time=  15.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.579, test=0.569) total time=  18.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.574) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=70;, score=(train=0.587, test=0.573) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.572) total time=   1.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.587, test=0.571) total time=   1.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=200;, score=(train=0.583, test=0.573) total time=   2.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=200;, score=(train=0.588, test=0.573) total time=   2.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=500;, score=(train=0.584, test=0.573) total time=   5.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=500;, score=(train=0.587, test=0.572) total time=   5.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.576) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.571) total time=   1.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.582, test=0.572) total time=  19.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.571) total time=  18.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=70;, score=(train=0.999, test=0.768) total time=   2.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=70;, score=(train=0.998, test=0.765) total time=   2.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.770) total time=   2.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.767) total time=   3.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=200;, score=(train=0.999, test=0.773) total time=   5.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=200;, score=(train=0.999, test=0.770) total time=   5.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.777) total time=  13.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=500;, score=(train=0.999, test=0.773) total time=  13.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.773) total time=   2.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.767) total time=   2.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.999, test=0.777) total time= 1.0min\n",
      "[CV 2/2] END criterion=entropy, max_depth=30, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.999, test=0.771) total time=  56.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=70;, score=(train=0.542, test=0.536) total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=70;, score=(train=0.552, test=0.549) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.553, test=0.550) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=200;, score=(train=0.549, test=0.540) total time=   1.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=500;, score=(train=0.550, test=0.545) total time=   4.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=500;, score=(train=0.553, test=0.549) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.542, test=0.538) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.548, test=0.545) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.542, test=0.534) total time=  19.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  14.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=70;, score=(train=0.565, test=0.561) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=70;, score=(train=0.570, test=0.565) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.560, test=0.555) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.559) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=200;, score=(train=0.562, test=0.558) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=200;, score=(train=0.568, test=0.562) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=500;, score=(train=0.560, test=0.558) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=500;, score=(train=0.570, test=0.562) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.561, test=0.557) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.570, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.564, test=0.559) total time=  17.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.568, test=0.563) total time=  16.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=70;, score=(train=0.572, test=0.566) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=70;, score=(train=0.571, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.575, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=200;, score=(train=0.571, test=0.563) total time=   1.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=200;, score=(train=0.571, test=0.565) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=500;, score=(train=0.572, test=0.565) total time=   4.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=500;, score=(train=0.578, test=0.569) total time=   4.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.564) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.576, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.564) total time=  16.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.576, test=0.567) total time=  16.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=70;, score=(train=0.573, test=0.567) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=70;, score=(train=0.574, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.568) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.579, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=200;, score=(train=0.573, test=0.565) total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=200;, score=(train=0.575, test=0.568) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=500;, score=(train=0.573, test=0.566) total time=   4.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=500;, score=(train=0.578, test=0.568) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.568, test=0.562) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.567) total time=  16.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.577, test=0.568) total time=  16.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=70;, score=(train=0.569, test=0.563) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=70;, score=(train=0.575, test=0.565) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.573, test=0.566) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.579, test=0.569) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=200;, score=(train=0.570, test=0.565) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=200;, score=(train=0.578, test=0.569) total time=   2.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=500;, score=(train=0.573, test=0.565) total time=   4.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=500;, score=(train=0.579, test=0.569) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.568) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.580, test=0.568) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.575, test=0.568) total time=  16.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.579, test=0.569) total time=  18.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=70;, score=(train=0.582, test=0.573) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=70;, score=(train=0.589, test=0.572) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.573) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.587, test=0.570) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=200;, score=(train=0.585, test=0.574) total time=   2.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=200;, score=(train=0.584, test=0.572) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.574) total time=   4.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=500;, score=(train=0.585, test=0.571) total time=   5.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.578, test=0.569) total time=   1.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.572) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.583, test=0.572) total time=  16.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  16.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.778) total time=   3.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.772) total time=   3.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.777) total time=   5.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.777) total time=   5.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.779) total time=  13.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.774) total time=  14.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.779) total time=   3.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.773) total time=   3.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.778) total time= 1.0min\n",
      "[CV 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.775) total time= 1.0min\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=70;, score=(train=0.550, test=0.548) total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=70;, score=(train=0.533, test=0.536) total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.550) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.558, test=0.555) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=200;, score=(train=0.545, test=0.540) total time=   1.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=500;, score=(train=0.542, test=0.534) total time=   3.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.549) total time=   3.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.543, test=0.534) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.551) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.549, test=0.542) total time=  14.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  14.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=70;, score=(train=0.565, test=0.559) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=70;, score=(train=0.564, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.561, test=0.551) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.573, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=200;, score=(train=0.561, test=0.555) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=200;, score=(train=0.568, test=0.559) total time=   1.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=500;, score=(train=0.564, test=0.560) total time=   4.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=500;, score=(train=0.573, test=0.564) total time=   4.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.560) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.573, test=0.564) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.567, test=0.561) total time=  15.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.570, test=0.562) total time=  17.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=70;, score=(train=0.572, test=0.563) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=70;, score=(train=0.568, test=0.560) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.570, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.563) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=200;, score=(train=0.570, test=0.564) total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=200;, score=(train=0.571, test=0.563) total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=500;, score=(train=0.573, test=0.565) total time=   4.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=500;, score=(train=0.578, test=0.568) total time=   4.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.567, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.560) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.571, test=0.564) total time=  16.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.573, test=0.566) total time=  16.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=70;, score=(train=0.571, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=70;, score=(train=0.573, test=0.564) total time=   0.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.574, test=0.568) total time=   1.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.565) total time=   1.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=200;, score=(train=0.572, test=0.566) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=200;, score=(train=0.579, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=500;, score=(train=0.573, test=0.567) total time=   4.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=500;, score=(train=0.578, test=0.567) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.573, test=0.568) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.580, test=0.571) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.566) total time=  16.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.577, test=0.569) total time=  18.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=70;, score=(train=0.572, test=0.567) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=70;, score=(train=0.577, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.571, test=0.564) total time=   0.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.580, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=200;, score=(train=0.572, test=0.565) total time=   2.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=200;, score=(train=0.578, test=0.569) total time=   2.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=500;, score=(train=0.579, test=0.569) total time=   4.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.573, test=0.567) total time=   0.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.576, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.577, test=0.568) total time=  16.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.580, test=0.570) total time=  17.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=70;, score=(train=0.582, test=0.572) total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=70;, score=(train=0.586, test=0.571) total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.578, test=0.568) total time=   1.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.587, test=0.569) total time=   1.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=200;, score=(train=0.581, test=0.571) total time=   2.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=200;, score=(train=0.585, test=0.572) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.572) total time=   5.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=500;, score=(train=0.587, test=0.573) total time=   4.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.574) total time=   1.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.569) total time=   1.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.582, test=0.572) total time=  18.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  18.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.777) total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.772) total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.776) total time=   2.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.776) total time=   2.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.777) total time=   5.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.773) total time=   5.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.776) total time=  14.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.775) total time=  15.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.776) total time=   3.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.773) total time=   2.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.780) total time= 1.0min\n",
      "[CV 2/2] END criterion=entropy, max_depth=None, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.773) total time= 1.0min\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=70;, score=(train=0.545, test=0.541) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=70;, score=(train=0.538, test=0.535) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.540, test=0.532) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.548) total time=   1.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=200;, score=(train=0.541, test=0.531) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=500;, score=(train=0.541, test=0.535) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=500;, score=(train=0.551, test=0.549) total time=   4.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.546) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.548) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.546) total time=  14.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.553, test=0.549) total time=  15.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=70;, score=(train=0.559, test=0.557) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=70;, score=(train=0.570, test=0.562) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.562, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.569, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=200;, score=(train=0.565, test=0.559) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=200;, score=(train=0.569, test=0.561) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=500;, score=(train=0.565, test=0.559) total time=   4.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=500;, score=(train=0.571, test=0.563) total time=   4.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.559) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=100;, score=(train=0.567, test=0.559) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.559) total time=  15.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.561) total time=  14.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=70;, score=(train=0.565, test=0.560) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=70;, score=(train=0.574, test=0.562) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.563) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.567, test=0.559) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=200;, score=(train=0.570, test=0.560) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=200;, score=(train=0.570, test=0.563) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=500;, score=(train=0.570, test=0.562) total time=   4.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=500;, score=(train=0.569, test=0.563) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.562, test=0.559) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=100;, score=(train=0.562, test=0.557) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.566, test=0.561) total time=  15.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.563) total time=  17.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=70;, score=(train=0.565, test=0.557) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=70;, score=(train=0.568, test=0.563) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.562, test=0.557) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.569, test=0.562) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=200;, score=(train=0.568, test=0.560) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=200;, score=(train=0.573, test=0.564) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=500;, score=(train=0.568, test=0.562) total time=   4.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=500;, score=(train=0.574, test=0.564) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.570, test=0.560) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.568, test=0.561) total time=  15.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.572, test=0.563) total time=  15.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=70;, score=(train=0.560, test=0.556) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=70;, score=(train=0.573, test=0.563) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.567, test=0.554) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=200;, score=(train=0.569, test=0.562) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=200;, score=(train=0.565, test=0.559) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=500;, score=(train=0.570, test=0.562) total time=   4.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=500;, score=(train=0.572, test=0.562) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.567, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=100;, score=(train=0.569, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.568, test=0.561) total time=  16.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.573, test=0.564) total time=  15.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=70;, score=(train=0.568, test=0.562) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=70;, score=(train=0.571, test=0.561) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.565, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=200;, score=(train=0.567, test=0.560) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=200;, score=(train=0.571, test=0.561) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=500;, score=(train=0.568, test=0.560) total time=   3.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=500;, score=(train=0.571, test=0.562) total time=   3.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.572, test=0.560) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=100;, score=(train=0.569, test=0.562) total time=   1.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.569, test=0.561) total time=  16.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.574, test=0.565) total time=  15.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=70;, score=(train=0.565, test=0.559) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=70;, score=(train=0.569, test=0.562) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.566, test=0.559) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.573, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=200;, score=(train=0.569, test=0.560) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=200;, score=(train=0.573, test=0.563) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=500;, score=(train=0.569, test=0.562) total time=   3.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=500;, score=(train=0.569, test=0.560) total time=   3.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.567, test=0.559) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=100;, score=(train=0.573, test=0.566) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.569, test=0.562) total time=  16.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=3, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.574, test=0.564) total time=  15.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=70;, score=(train=0.556, test=0.553) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=70;, score=(train=0.552, test=0.549) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.553, test=0.549) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.540, test=0.538) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=200;, score=(train=0.537, test=0.527) total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=200;, score=(train=0.547, test=0.543) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=500;, score=(train=0.553, test=0.548) total time=   3.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=500;, score=(train=0.551, test=0.548) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.550, test=0.549) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.551) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.547, test=0.540) total time=  14.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  15.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=70;, score=(train=0.557, test=0.555) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=70;, score=(train=0.566, test=0.562) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.563, test=0.559) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.557) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=200;, score=(train=0.564, test=0.559) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=200;, score=(train=0.570, test=0.562) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=500;, score=(train=0.564, test=0.559) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=500;, score=(train=0.572, test=0.561) total time=   4.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.562) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=100;, score=(train=0.568, test=0.562) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.564, test=0.560) total time=  16.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.571, test=0.563) total time=  16.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=70;, score=(train=0.571, test=0.567) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=70;, score=(train=0.574, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.571, test=0.562) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=200;, score=(train=0.572, test=0.564) total time=   2.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=200;, score=(train=0.576, test=0.565) total time=   1.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=500;, score=(train=0.570, test=0.564) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=500;, score=(train=0.574, test=0.565) total time=   4.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.568, test=0.562) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=100;, score=(train=0.577, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.571, test=0.564) total time=  17.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.573, test=0.565) total time=  15.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=70;, score=(train=0.571, test=0.564) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=70;, score=(train=0.572, test=0.564) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.565) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=200;, score=(train=0.572, test=0.564) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=200;, score=(train=0.576, test=0.566) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=500;, score=(train=0.572, test=0.565) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=500;, score=(train=0.577, test=0.568) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.569) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.567) total time=  15.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.577, test=0.567) total time=  15.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=70;, score=(train=0.584, test=0.574) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=70;, score=(train=0.576, test=0.567) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.576, test=0.567) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=200;, score=(train=0.576, test=0.566) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=200;, score=(train=0.578, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=500;, score=(train=0.575, test=0.568) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=500;, score=(train=0.578, test=0.569) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.578, test=0.570) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.568) total time=  15.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.580, test=0.570) total time=  15.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=70;, score=(train=0.580, test=0.571) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=70;, score=(train=0.586, test=0.570) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.578, test=0.571) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=200;, score=(train=0.582, test=0.571) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=200;, score=(train=0.583, test=0.570) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.572) total time=   4.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=500;, score=(train=0.584, test=0.571) total time=   4.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.572) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=100;, score=(train=0.586, test=0.571) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.582, test=0.572) total time=  16.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  16.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=70;, score=(train=0.607, test=0.581) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=70;, score=(train=0.617, test=0.583) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.612, test=0.586) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.619, test=0.585) total time=   1.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=200;, score=(train=0.614, test=0.588) total time=   2.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=200;, score=(train=0.610, test=0.580) total time=   2.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=500;, score=(train=0.614, test=0.588) total time=   5.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=500;, score=(train=0.615, test=0.583) total time=   5.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.611, test=0.585) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=100;, score=(train=0.617, test=0.583) total time=   1.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.616, test=0.588) total time=  19.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.614, test=0.583) total time=  19.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=70;, score=(train=0.550, test=0.548) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=70;, score=(train=0.551, test=0.549) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.554, test=0.552) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.548, test=0.543) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=200;, score=(train=0.551, test=0.550) total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=500;, score=(train=0.547, test=0.544) total time=   3.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=500;, score=(train=0.551, test=0.548) total time=   3.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.539, test=0.534) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=100;, score=(train=0.553, test=0.551) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.550, test=0.546) total time=  13.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  13.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=70;, score=(train=0.563, test=0.560) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=70;, score=(train=0.569, test=0.560) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.559, test=0.556) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.569, test=0.561) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=200;, score=(train=0.563, test=0.559) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=200;, score=(train=0.569, test=0.563) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=500;, score=(train=0.561, test=0.557) total time=   3.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=500;, score=(train=0.569, test=0.561) total time=   3.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.560, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=100;, score=(train=0.574, test=0.567) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.558) total time=  14.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.570, test=0.562) total time=  14.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=70;, score=(train=0.571, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=70;, score=(train=0.575, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.569, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.573, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=200;, score=(train=0.572, test=0.567) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=200;, score=(train=0.577, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=500;, score=(train=0.572, test=0.565) total time=   3.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=500;, score=(train=0.573, test=0.564) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.571, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.564) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.565) total time=  15.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.574, test=0.566) total time=  15.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=70;, score=(train=0.568, test=0.562) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=70;, score=(train=0.573, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.572, test=0.563) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.579, test=0.569) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=200;, score=(train=0.571, test=0.566) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=500;, score=(train=0.575, test=0.565) total time=   4.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=500;, score=(train=0.576, test=0.566) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.567) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=100;, score=(train=0.579, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.575, test=0.567) total time=  15.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.578, test=0.569) total time=  15.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=70;, score=(train=0.571, test=0.563) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=70;, score=(train=0.573, test=0.563) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.565) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.580, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=200;, score=(train=0.580, test=0.569) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=500;, score=(train=0.577, test=0.568) total time=   4.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=500;, score=(train=0.578, test=0.568) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.568, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=100;, score=(train=0.579, test=0.569) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.568) total time=  15.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.579, test=0.568) total time=  15.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=70;, score=(train=0.581, test=0.573) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=70;, score=(train=0.583, test=0.569) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.573) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=200;, score=(train=0.584, test=0.574) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=200;, score=(train=0.584, test=0.570) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.572) total time=   4.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=500;, score=(train=0.586, test=0.571) total time=   4.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.572) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.584, test=0.572) total time=  16.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  16.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=70;, score=(train=0.665, test=0.612) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=70;, score=(train=0.654, test=0.600) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.664, test=0.606) total time=   1.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.661, test=0.600) total time=   1.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=200;, score=(train=0.659, test=0.608) total time=   2.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=200;, score=(train=0.662, test=0.606) total time=   2.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=500;, score=(train=0.662, test=0.608) total time=   5.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=500;, score=(train=0.662, test=0.601) total time=   5.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.667, test=0.612) total time=   1.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=100;, score=(train=0.662, test=0.603) total time=   1.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.667, test=0.612) total time=  21.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.659, test=0.603) total time=  21.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=70;, score=(train=0.538, test=0.530) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=70;, score=(train=0.546, test=0.543) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.538, test=0.529) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=200;, score=(train=0.548, test=0.541) total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=200;, score=(train=0.552, test=0.549) total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=500;, score=(train=0.550, test=0.543) total time=   3.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.547) total time=   3.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.549, test=0.544) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.544, test=0.535) total time=  13.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  13.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=70;, score=(train=0.561, test=0.559) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=70;, score=(train=0.564, test=0.560) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.560) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=200;, score=(train=0.567, test=0.561) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=200;, score=(train=0.572, test=0.564) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=500;, score=(train=0.565, test=0.560) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=500;, score=(train=0.568, test=0.561) total time=   3.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.563, test=0.558) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=100;, score=(train=0.568, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.562, test=0.559) total time=  14.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.570, test=0.564) total time=  14.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=70;, score=(train=0.571, test=0.566) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=70;, score=(train=0.576, test=0.568) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.570, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.578, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=200;, score=(train=0.566, test=0.559) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=200;, score=(train=0.577, test=0.569) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=500;, score=(train=0.572, test=0.565) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.572, test=0.562) total time=   1.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.566) total time=  15.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.575, test=0.566) total time=  15.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=70;, score=(train=0.567, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=70;, score=(train=0.575, test=0.564) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.568) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=200;, score=(train=0.574, test=0.566) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=200;, score=(train=0.574, test=0.564) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=500;, score=(train=0.575, test=0.567) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=500;, score=(train=0.578, test=0.569) total time=   4.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.570, test=0.565) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=100;, score=(train=0.577, test=0.569) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.575, test=0.566) total time=  15.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.577, test=0.568) total time=  15.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=70;, score=(train=0.575, test=0.564) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=70;, score=(train=0.580, test=0.568) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.573, test=0.568) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.568) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=200;, score=(train=0.578, test=0.569) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=200;, score=(train=0.578, test=0.569) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=500;, score=(train=0.578, test=0.569) total time=   4.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.570) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.568) total time=  15.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.580, test=0.570) total time=  16.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=70;, score=(train=0.580, test=0.569) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=70;, score=(train=0.583, test=0.570) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.574) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=200;, score=(train=0.582, test=0.571) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=200;, score=(train=0.586, test=0.572) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=500;, score=(train=0.585, test=0.573) total time=   4.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=500;, score=(train=0.584, test=0.571) total time=   4.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.581, test=0.574) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.583, test=0.572) total time=  16.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.588, test=0.573) total time=  16.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=70;, score=(train=0.877, test=0.694) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=70;, score=(train=0.868, test=0.691) total time=   1.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.877, test=0.695) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.866, test=0.690) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=200;, score=(train=0.876, test=0.696) total time=   3.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=200;, score=(train=0.873, test=0.691) total time=   3.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=500;, score=(train=0.884, test=0.699) total time=   7.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=500;, score=(train=0.877, test=0.694) total time=   7.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.871, test=0.692) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=100;, score=(train=0.871, test=0.692) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.885, test=0.700) total time=  31.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.879, test=0.695) total time=  31.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=70;, score=(train=0.551, test=0.548) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=70;, score=(train=0.538, test=0.534) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.538, test=0.528) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=200;, score=(train=0.551, test=0.550) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=200;, score=(train=0.553, test=0.548) total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=500;, score=(train=0.538, test=0.528) total time=   3.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.548) total time=   3.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.536, test=0.529) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=100;, score=(train=0.538, test=0.535) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.553, test=0.549) total time=  13.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  13.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=70;, score=(train=0.564, test=0.561) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=70;, score=(train=0.566, test=0.558) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.566, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.568, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=200;, score=(train=0.562, test=0.558) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=200;, score=(train=0.567, test=0.561) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=500;, score=(train=0.565, test=0.561) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=500;, score=(train=0.569, test=0.563) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.563, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=100;, score=(train=0.568, test=0.561) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.564, test=0.560) total time=  15.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.563) total time=  14.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=70;, score=(train=0.568, test=0.562) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=70;, score=(train=0.573, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.573, test=0.568) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.571, test=0.564) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=200;, score=(train=0.572, test=0.568) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=200;, score=(train=0.576, test=0.565) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=500;, score=(train=0.572, test=0.566) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=500;, score=(train=0.577, test=0.568) total time=   4.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.570, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=100;, score=(train=0.576, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.571, test=0.564) total time=  16.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.575, test=0.567) total time=  16.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=70;, score=(train=0.571, test=0.564) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=70;, score=(train=0.569, test=0.562) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.563) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=200;, score=(train=0.576, test=0.569) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=200;, score=(train=0.576, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=500;, score=(train=0.575, test=0.566) total time=   4.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=500;, score=(train=0.576, test=0.568) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=100;, score=(train=0.574, test=0.565) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.567) total time=  15.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.575, test=0.567) total time=  15.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=70;, score=(train=0.573, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=70;, score=(train=0.576, test=0.568) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.574, test=0.567) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.576, test=0.564) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=200;, score=(train=0.577, test=0.568) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=200;, score=(train=0.579, test=0.569) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=500;, score=(train=0.579, test=0.569) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.573, test=0.569) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=100;, score=(train=0.577, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.578, test=0.568) total time=  16.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.579, test=0.568) total time=  16.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=70;, score=(train=0.582, test=0.572) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.571) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.574) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.586, test=0.571) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=200;, score=(train=0.584, test=0.572) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=200;, score=(train=0.584, test=0.573) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.573) total time=   4.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=500;, score=(train=0.587, test=0.572) total time=   4.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.588, test=0.573) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.584, test=0.573) total time=  16.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.588, test=0.573) total time=  16.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=70;, score=(train=0.999, test=0.772) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=70;, score=(train=0.999, test=0.767) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.772) total time=   2.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.770) total time=   2.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.772) total time=   4.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=200;, score=(train=0.999, test=0.771) total time=   4.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.778) total time=  12.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=500;, score=(train=0.999, test=0.772) total time=  12.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.774) total time=   2.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=100;, score=(train=0.999, test=0.771) total time=   2.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.777) total time=  50.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=30, max_leaf_nodes=None, n_estimators=2000;, score=(train=0.999, test=0.774) total time=  50.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=70;, score=(train=0.552, test=0.548) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=70;, score=(train=0.551, test=0.549) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.540, test=0.529) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.552, test=0.549) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=200;, score=(train=0.538, test=0.529) total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=200;, score=(train=0.545, test=0.544) total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=500;, score=(train=0.543, test=0.535) total time=   3.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.548) total time=   3.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.536, test=0.529) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=100;, score=(train=0.547, test=0.541) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.545, test=0.539) total time=  13.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.552, test=0.549) total time=  13.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=70;, score=(train=0.557, test=0.556) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=70;, score=(train=0.567, test=0.560) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.559, test=0.552) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.565, test=0.560) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=200;, score=(train=0.560, test=0.556) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=200;, score=(train=0.571, test=0.563) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=500;, score=(train=0.566, test=0.562) total time=   3.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=500;, score=(train=0.573, test=0.566) total time=   3.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.561) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=100;, score=(train=0.571, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.559) total time=  14.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.569, test=0.563) total time=  14.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=70;, score=(train=0.574, test=0.566) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=70;, score=(train=0.572, test=0.561) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.571, test=0.564) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=200;, score=(train=0.566, test=0.562) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=200;, score=(train=0.577, test=0.564) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=500;, score=(train=0.571, test=0.566) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=500;, score=(train=0.575, test=0.567) total time=   4.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.573, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=100;, score=(train=0.573, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.564) total time=  15.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.574, test=0.566) total time=  15.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=70;, score=(train=0.573, test=0.569) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=70;, score=(train=0.574, test=0.565) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.572, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.577, test=0.566) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=200;, score=(train=0.571, test=0.564) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=500;, score=(train=0.574, test=0.567) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=500;, score=(train=0.574, test=0.566) total time=   4.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.575, test=0.568) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=100;, score=(train=0.576, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.575, test=0.567) total time=  15.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.577, test=0.568) total time=  15.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=70;, score=(train=0.570, test=0.563) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=70;, score=(train=0.578, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.566) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.576, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=200;, score=(train=0.575, test=0.567) total time=   1.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=200;, score=(train=0.579, test=0.568) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=500;, score=(train=0.577, test=0.570) total time=   4.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=500;, score=(train=0.577, test=0.567) total time=   4.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.571, test=0.562) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=100;, score=(train=0.578, test=0.567) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.568) total time=  15.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.578, test=0.569) total time=  15.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.574) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=70;, score=(train=0.583, test=0.572) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.575) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.584, test=0.570) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=200;, score=(train=0.581, test=0.570) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=200;, score=(train=0.585, test=0.571) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=500;, score=(train=0.582, test=0.573) total time=   4.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=500;, score=(train=0.587, test=0.572) total time=   4.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.585, test=0.574) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.570) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.583, test=0.573) total time=  16.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.586, test=0.572) total time=  16.4s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.773) total time=   1.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.777) total time=   2.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.775) total time=   2.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.778) total time=   4.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.776) total time=   5.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.781) total time=  12.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.777) total time=  12.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.779) total time=   2.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.773) total time=   2.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.781) total time=  51.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=50, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.776) total time=  49.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=70;, score=(train=0.546, test=0.543) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=70;, score=(train=0.553, test=0.552) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.543, test=0.542) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.548) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=200;, score=(train=0.543, test=0.538) total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=200;, score=(train=0.553, test=0.549) total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=500;, score=(train=0.544, test=0.537) total time=   3.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=500;, score=(train=0.552, test=0.549) total time=   3.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.550, test=0.546) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=100;, score=(train=0.551, test=0.548) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.542, test=0.533) total time=  13.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=2, n_estimators=2000;, score=(train=0.551, test=0.549) total time=  13.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=70;, score=(train=0.561, test=0.556) total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=70;, score=(train=0.576, test=0.567) total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.564, test=0.558) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.567, test=0.560) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=200;, score=(train=0.562, test=0.557) total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=200;, score=(train=0.569, test=0.564) total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=500;, score=(train=0.561, test=0.557) total time=   3.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=500;, score=(train=0.567, test=0.561) total time=   4.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.559, test=0.554) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=100;, score=(train=0.563, test=0.556) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.563, test=0.559) total time=  16.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=5, n_estimators=2000;, score=(train=0.570, test=0.563) total time=  15.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=70;, score=(train=0.566, test=0.563) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=70;, score=(train=0.578, test=0.566) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.569, test=0.564) total time=   1.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.574, test=0.563) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=200;, score=(train=0.566, test=0.561) total time=   1.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=200;, score=(train=0.574, test=0.564) total time=   1.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=500;, score=(train=0.570, test=0.563) total time=   4.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=500;, score=(train=0.574, test=0.568) total time=   4.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.567, test=0.561) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=100;, score=(train=0.578, test=0.569) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.572, test=0.565) total time=  19.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=7, n_estimators=2000;, score=(train=0.574, test=0.567) total time=  16.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=70;, score=(train=0.570, test=0.565) total time=   0.7s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=70;, score=(train=0.574, test=0.563) total time=   0.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.571, test=0.564) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.578, test=0.569) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=200;, score=(train=0.570, test=0.564) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=200;, score=(train=0.578, test=0.567) total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=500;, score=(train=0.573, test=0.568) total time=   4.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=500;, score=(train=0.577, test=0.570) total time=   4.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.569, test=0.562) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=100;, score=(train=0.577, test=0.568) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.574, test=0.566) total time=  17.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=8, n_estimators=2000;, score=(train=0.576, test=0.567) total time=  18.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=70;, score=(train=0.571, test=0.565) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=70;, score=(train=0.576, test=0.565) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.576, test=0.567) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.578, test=0.568) total time=   1.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=200;, score=(train=0.572, test=0.563) total time=   2.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=200;, score=(train=0.580, test=0.570) total time=   1.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=500;, score=(train=0.574, test=0.565) total time=   4.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=500;, score=(train=0.578, test=0.568) total time=   5.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.575, test=0.567) total time=   1.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=100;, score=(train=0.581, test=0.570) total time=   1.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.576, test=0.567) total time=  16.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=9, n_estimators=2000;, score=(train=0.578, test=0.568) total time=  16.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=70;, score=(train=0.582, test=0.569) total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=70;, score=(train=0.584, test=0.570) total time=   0.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.580, test=0.571) total time=   1.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.582, test=0.569) total time=   1.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=200;, score=(train=0.583, test=0.573) total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=200;, score=(train=0.583, test=0.571) total time=   1.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=500;, score=(train=0.583, test=0.571) total time=   4.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=500;, score=(train=0.584, test=0.571) total time=   4.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.583, test=0.572) total time=   0.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=100;, score=(train=0.586, test=0.572) total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.582, test=0.572) total time=  17.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=15, n_estimators=2000;, score=(train=0.585, test=0.572) total time=  17.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.778) total time=   1.9s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=70;, score=(train=1.000, test=0.775) total time=   1.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.777) total time=   2.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.774) total time=   2.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.780) total time=   5.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=200;, score=(train=1.000, test=0.778) total time=   5.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.779) total time=  13.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=500;, score=(train=1.000, test=0.776) total time=  14.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.778) total time=   2.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=100;, score=(train=1.000, test=0.776) total time=   2.8s\n",
      "[CV 1/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.780) total time=  51.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=None, max_leaf_nodes=None, n_estimators=2000;, score=(train=1.000, test=0.776) total time=  53.3s\n"
     ]
    }
   ],
   "source": [
    "grid_rforest.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ec1b8600-c08b-4128-b402-cdafd064ac1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692484</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>0.095787</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.528670</td>\n",
       "      <td>0.549098</td>\n",
       "      <td>0.538884</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>579</td>\n",
       "      <td>0.536945</td>\n",
       "      <td>0.551587</td>\n",
       "      <td>0.544266</td>\n",
       "      <td>0.007321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.876325</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>0.098976</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.550520</td>\n",
       "      <td>0.550585</td>\n",
       "      <td>0.550553</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>508</td>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.551619</td>\n",
       "      <td>0.551167</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.576537</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.165728</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.534424</td>\n",
       "      <td>0.547611</td>\n",
       "      <td>0.541018</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>567</td>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.550844</td>\n",
       "      <td>0.545720</td>\n",
       "      <td>0.005123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.660506</td>\n",
       "      <td>0.057267</td>\n",
       "      <td>0.349392</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.542246</td>\n",
       "      <td>0.549421</td>\n",
       "      <td>0.545834</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>536</td>\n",
       "      <td>0.547708</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.549728</td>\n",
       "      <td>0.002020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.870473</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.101487</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.548807</td>\n",
       "      <td>0.550391</td>\n",
       "      <td>0.549599</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>512</td>\n",
       "      <td>0.549971</td>\n",
       "      <td>0.551296</td>\n",
       "      <td>0.550634</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2.421008</td>\n",
       "      <td>0.049993</td>\n",
       "      <td>0.262492</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.776909</td>\n",
       "      <td>0.773579</td>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>4.876010</td>\n",
       "      <td>0.206990</td>\n",
       "      <td>0.574489</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.779850</td>\n",
       "      <td>0.777652</td>\n",
       "      <td>0.778751</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>12.264705</td>\n",
       "      <td>0.522295</td>\n",
       "      <td>1.533107</td>\n",
       "      <td>0.184894</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.778945</td>\n",
       "      <td>0.775680</td>\n",
       "      <td>0.777313</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2.607009</td>\n",
       "      <td>0.026009</td>\n",
       "      <td>0.305094</td>\n",
       "      <td>0.022909</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.778396</td>\n",
       "      <td>0.776004</td>\n",
       "      <td>0.777200</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>47.181948</td>\n",
       "      <td>0.971035</td>\n",
       "      <td>5.387999</td>\n",
       "      <td>0.101999</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.779915</td>\n",
       "      <td>0.776230</td>\n",
       "      <td>0.778072</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.692484      0.017465         0.095787        0.023797   \n",
       "1         0.876325      0.015506         0.098976        0.003998   \n",
       "2         1.576537      0.015613         0.165728        0.000269   \n",
       "3         3.660506      0.057267         0.349392        0.010410   \n",
       "4         0.870473      0.001480         0.101487        0.004493   \n",
       "..             ...           ...              ...             ...   \n",
       "583       2.421008      0.049993         0.262492        0.000509   \n",
       "584       4.876010      0.206990         0.574489        0.017488   \n",
       "585      12.264705      0.522295         1.533107        0.184894   \n",
       "586       2.607009      0.026009         0.305094        0.022909   \n",
       "587      47.181948      0.971035         5.387999        0.101999   \n",
       "\n",
       "    param_criterion param_max_depth param_max_leaf_nodes param_n_estimators  \\\n",
       "0           entropy               3                    2                 70   \n",
       "1           entropy               3                    2                100   \n",
       "2           entropy               3                    2                200   \n",
       "3           entropy               3                    2                500   \n",
       "4           entropy               3                    2                100   \n",
       "..              ...             ...                  ...                ...   \n",
       "583            gini            None                 None                100   \n",
       "584            gini            None                 None                200   \n",
       "585            gini            None                 None                500   \n",
       "586            gini            None                 None                100   \n",
       "587            gini            None                 None               2000   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'criterion': 'entropy', 'max_depth': 3, 'max_...           0.528670   \n",
       "1    {'criterion': 'entropy', 'max_depth': 3, 'max_...           0.550520   \n",
       "2    {'criterion': 'entropy', 'max_depth': 3, 'max_...           0.534424   \n",
       "3    {'criterion': 'entropy', 'max_depth': 3, 'max_...           0.542246   \n",
       "4    {'criterion': 'entropy', 'max_depth': 3, 'max_...           0.548807   \n",
       "..                                                 ...                ...   \n",
       "583  {'criterion': 'gini', 'max_depth': None, 'max_...           0.776909   \n",
       "584  {'criterion': 'gini', 'max_depth': None, 'max_...           0.779850   \n",
       "585  {'criterion': 'gini', 'max_depth': None, 'max_...           0.778945   \n",
       "586  {'criterion': 'gini', 'max_depth': None, 'max_...           0.778396   \n",
       "587  {'criterion': 'gini', 'max_depth': None, 'max_...           0.779915   \n",
       "\n",
       "     split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0             0.549098         0.538884        0.010214              579   \n",
       "1             0.550585         0.550553        0.000032              508   \n",
       "2             0.547611         0.541018        0.006594              567   \n",
       "3             0.549421         0.545834        0.003588              536   \n",
       "4             0.550391         0.549599        0.000792              512   \n",
       "..                 ...              ...             ...              ...   \n",
       "583           0.773579         0.775244        0.001665               20   \n",
       "584           0.777652         0.778751        0.001099                2   \n",
       "585           0.775680         0.777313        0.001632                5   \n",
       "586           0.776004         0.777200        0.001196                6   \n",
       "587           0.776230         0.778072        0.001842                4   \n",
       "\n",
       "     split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "0              0.536945            0.551587          0.544266         0.007321  \n",
       "1              0.550714            0.551619          0.551167         0.000453  \n",
       "2              0.540597            0.550844          0.545720         0.005123  \n",
       "3              0.547708            0.551749          0.549728         0.002020  \n",
       "4              0.549971            0.551296          0.550634         0.000663  \n",
       "..                  ...                 ...               ...              ...  \n",
       "583            1.000000            1.000000          1.000000         0.000000  \n",
       "584            1.000000            1.000000          1.000000         0.000000  \n",
       "585            1.000000            1.000000          1.000000         0.000000  \n",
       "586            1.000000            1.000000          1.000000         0.000000  \n",
       "587            1.000000            1.000000          1.000000         0.000000  \n",
       "\n",
       "[588 rows x 18 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridDecisionTree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1c6e697c-e75a-4fc1-baf7-d5e77c947993",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = gridDecisionTree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1a62ed19-eda4-4e63-8783-4f8baa5eb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "60c06baf-61ef-4ecc-9e3c-9ed3024db607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90      7750\n",
      "           1       0.88      0.94      0.91      7720\n",
      "\n",
      "    accuracy                           0.91     15470\n",
      "   macro avg       0.91      0.91      0.91     15470\n",
      "weighted avg       0.91      0.91      0.91     15470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste = best.predict(X_test)\n",
    "print(classification_report(y_test, teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc7588-b390-4e68-9131-2bf0380c8ff7",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f617c-f83d-4333-8475-8f65163db779",
   "metadata": {},
   "source": [
    "adaboost - smote-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2e8f08e7-f471-4d5a-b961-6c0dc7e5b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state = 1216)\n",
    "X, y = df_splitter(datasets['smoted-'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9445b8aa-0e6d-4abe-9695-d94c6c24e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search parameters\n",
    "n_estimators = np.array([70,100,150,200,300,500,600])\n",
    "learning_rate = np.array([0.5,1,1.5,2,3,5,10])\n",
    "values_grid = {'n_estimators': n_estimators, 'learning_rate': learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "006a581e-5083-46da-841f-f153674a054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridDecisionTree = GridSearchCV(estimator = ada_boost,\n",
    "                                param_grid = values_grid,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1,\n",
    "                                return_train_score= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e681e37f-b024-4629-b332-4c04c784b40d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 49 candidates, totalling 98 fits\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=70;, score=(train=0.785, test=0.788) total time=   2.6s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=70;, score=(train=0.788, test=0.785) total time=   2.6s\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=100;, score=(train=0.793, test=0.796) total time=   3.8s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=100;, score=(train=0.797, test=0.793) total time=   4.0s\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=150;, score=(train=0.802, test=0.805) total time=   5.5s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=150;, score=(train=0.806, test=0.804) total time=   5.5s\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=200;, score=(train=0.809, test=0.810) total time=   7.6s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=200;, score=(train=0.810, test=0.807) total time=   6.9s\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=300;, score=(train=0.811, test=0.813) total time=  10.8s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=300;, score=(train=0.814, test=0.811) total time=  10.5s\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=500;, score=(train=0.815, test=0.816) total time=  17.8s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=500;, score=(train=0.817, test=0.815) total time=  18.2s\n",
      "[CV 1/2] END learning_rate=0.5, n_estimators=600;, score=(train=0.816, test=0.817) total time=  21.4s\n",
      "[CV 2/2] END learning_rate=0.5, n_estimators=600;, score=(train=0.818, test=0.816) total time=  21.2s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=70;, score=(train=0.780, test=0.781) total time=   2.5s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=70;, score=(train=0.788, test=0.786) total time=   2.4s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=100;, score=(train=0.799, test=0.800) total time=   3.6s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=100;, score=(train=0.803, test=0.801) total time=   3.5s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=150;, score=(train=0.809, test=0.811) total time=   5.5s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=150;, score=(train=0.813, test=0.810) total time=   5.4s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=200;, score=(train=0.814, test=0.816) total time=   7.3s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=200;, score=(train=0.817, test=0.814) total time=   7.3s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=300;, score=(train=0.817, test=0.818) total time=  10.7s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=300;, score=(train=0.818, test=0.815) total time=  10.8s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=500;, score=(train=0.818, test=0.818) total time=  19.0s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=500;, score=(train=0.819, test=0.817) total time=  18.8s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=600;, score=(train=0.818, test=0.819) total time=  20.1s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=600;, score=(train=0.820, test=0.817) total time=  21.1s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=70;, score=(train=0.785, test=0.788) total time=   2.4s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=70;, score=(train=0.783, test=0.782) total time=   2.4s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=100;, score=(train=0.814, test=0.817) total time=   3.4s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=100;, score=(train=0.819, test=0.816) total time=   3.3s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=150;, score=(train=0.817, test=0.819) total time=   5.0s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=150;, score=(train=0.819, test=0.816) total time=   5.0s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=200;, score=(train=0.817, test=0.819) total time=   6.9s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=200;, score=(train=0.819, test=0.817) total time=   7.1s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=300;, score=(train=0.818, test=0.819) total time=  10.4s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=300;, score=(train=0.819, test=0.817) total time=  10.1s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=500;, score=(train=0.818, test=0.818) total time=  17.6s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=500;, score=(train=0.819, test=0.816) total time=  16.8s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=600;, score=(train=0.818, test=0.818) total time=  20.3s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=600;, score=(train=0.819, test=0.816) total time=  20.2s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=70;, score=(train=0.614, test=0.612) total time=   2.3s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=70;, score=(train=0.612, test=0.614) total time=   2.3s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=100;, score=(train=0.614, test=0.612) total time=   3.3s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=100;, score=(train=0.612, test=0.614) total time=   3.5s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=150;, score=(train=0.614, test=0.612) total time=   5.2s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=150;, score=(train=0.612, test=0.614) total time=   5.1s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=200;, score=(train=0.614, test=0.612) total time=   6.7s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=200;, score=(train=0.612, test=0.614) total time=   6.7s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=300;, score=(train=0.614, test=0.612) total time=  10.0s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=300;, score=(train=0.612, test=0.614) total time=  10.1s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=500;, score=(train=0.614, test=0.612) total time=  16.8s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=500;, score=(train=0.612, test=0.614) total time=  16.8s\n",
      "[CV 1/2] END learning_rate=2.0, n_estimators=600;, score=(train=0.614, test=0.612) total time=  20.1s\n",
      "[CV 2/2] END learning_rate=2.0, n_estimators=600;, score=(train=0.612, test=0.614) total time=  20.3s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=70;, score=(train=0.438, test=0.438) total time=   2.3s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=70;, score=(train=0.438, test=0.438) total time=   2.3s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=100;, score=(train=0.438, test=0.438) total time=   3.3s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=100;, score=(train=0.438, test=0.438) total time=   3.3s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=150;, score=(train=0.438, test=0.438) total time=   5.1s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=150;, score=(train=0.438, test=0.438) total time=   5.1s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=200;, score=(train=0.438, test=0.438) total time=   6.8s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=200;, score=(train=0.438, test=0.438) total time=   6.7s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=300;, score=(train=0.438, test=0.438) total time=  10.2s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=300;, score=(train=0.438, test=0.438) total time=  10.2s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=500;, score=(train=0.438, test=0.438) total time=  17.1s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=500;, score=(train=0.438, test=0.438) total time=  22.1s\n",
      "[CV 1/2] END learning_rate=3.0, n_estimators=600;, score=(train=0.438, test=0.438) total time=  22.2s\n",
      "[CV 2/2] END learning_rate=3.0, n_estimators=600;, score=(train=0.438, test=0.438) total time=  25.6s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=70;, score=(train=0.438, test=0.438) total time=   1.7s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=70;, score=(train=0.438, test=0.438) total time=   1.8s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=100;, score=(train=0.438, test=0.438) total time=   2.4s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=100;, score=(train=0.438, test=0.438) total time=   2.3s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=150;, score=(train=0.438, test=0.438) total time=   3.6s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=150;, score=(train=0.438, test=0.438) total time=   3.5s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=200;, score=(train=0.438, test=0.438) total time=   4.7s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=200;, score=(train=0.438, test=0.438) total time=   4.8s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=300;, score=(train=0.438, test=0.438) total time=   8.2s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=300;, score=(train=0.438, test=0.438) total time=   8.6s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=500;, score=(train=0.438, test=0.438) total time=  13.7s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=500;, score=(train=0.438, test=0.438) total time=  13.1s\n",
      "[CV 1/2] END learning_rate=5.0, n_estimators=600;, score=(train=0.438, test=0.438) total time=  15.5s\n",
      "[CV 2/2] END learning_rate=5.0, n_estimators=600;, score=(train=0.438, test=0.438) total time=  16.9s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=70;, score=(train=0.500, test=0.500) total time=   1.9s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=70;, score=(train=0.500, test=0.500) total time=   1.9s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=100;, score=(train=0.500, test=0.500) total time=   2.5s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=100;, score=(train=0.500, test=0.500) total time=   2.5s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=150;, score=(train=0.500, test=0.500) total time=   3.9s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=150;, score=(train=0.500, test=0.500) total time=   3.9s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=200;, score=(train=0.500, test=0.500) total time=   5.3s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=200;, score=(train=0.500, test=0.500) total time=   5.3s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=300;, score=(train=0.500, test=0.500) total time=   8.6s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=300;, score=(train=0.500, test=0.500) total time=   8.6s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=500;, score=(train=0.500, test=0.500) total time=  12.8s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=500;, score=(train=0.500, test=0.500) total time=  14.7s\n",
      "[CV 1/2] END learning_rate=10.0, n_estimators=600;, score=(train=0.500, test=0.500) total time=  14.8s\n",
      "[CV 2/2] END learning_rate=10.0, n_estimators=600;, score=(train=0.500, test=0.500) total time=  14.6s\n"
     ]
    }
   ],
   "source": [
    "gridDecisionTree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2b03e088-6f5e-4d75-a8d5-8bfb9ddc7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada3 = pd.DataFrame(gridDecisionTree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ce29a294-3f65-47c4-9023-def71bce4c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.521178</td>\n",
       "      <td>1.588398e-01</td>\n",
       "      <td>1.555501</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>1.5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 200}</td>\n",
       "      <td>0.819066</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.817814</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817220</td>\n",
       "      <td>0.819099</td>\n",
       "      <td>0.818159</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.054733</td>\n",
       "      <td>1.282513e-01</td>\n",
       "      <td>2.292000</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>1.5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 300}</td>\n",
       "      <td>0.818770</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.817716</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>2</td>\n",
       "      <td>0.817614</td>\n",
       "      <td>0.819296</td>\n",
       "      <td>0.818455</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.096500</td>\n",
       "      <td>3.765002e-01</td>\n",
       "      <td>4.601483</td>\n",
       "      <td>0.114499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 600}</td>\n",
       "      <td>0.818573</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.817617</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>3</td>\n",
       "      <td>0.817713</td>\n",
       "      <td>0.819986</td>\n",
       "      <td>0.818849</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.478000</td>\n",
       "      <td>2.290028e-01</td>\n",
       "      <td>4.492502</td>\n",
       "      <td>0.145502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 500}</td>\n",
       "      <td>0.818474</td>\n",
       "      <td>0.816629</td>\n",
       "      <td>0.817552</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.819427</td>\n",
       "      <td>0.818537</td>\n",
       "      <td>0.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.951005</td>\n",
       "      <td>6.437302e-06</td>\n",
       "      <td>1.111511</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>1.5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 150}</td>\n",
       "      <td>0.818836</td>\n",
       "      <td>0.815840</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>5</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.819263</td>\n",
       "      <td>0.817962</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.603209</td>\n",
       "      <td>3.968124e-01</td>\n",
       "      <td>3.716492</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>1.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 500}</td>\n",
       "      <td>0.818442</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.817289</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>6</td>\n",
       "      <td>0.817943</td>\n",
       "      <td>0.819131</td>\n",
       "      <td>0.818537</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.790011</td>\n",
       "      <td>6.699562e-02</td>\n",
       "      <td>4.536492</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>1.5</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 600}</td>\n",
       "      <td>0.818376</td>\n",
       "      <td>0.815972</td>\n",
       "      <td>0.817174</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>7</td>\n",
       "      <td>0.817812</td>\n",
       "      <td>0.819131</td>\n",
       "      <td>0.818471</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.399500</td>\n",
       "      <td>6.149924e-02</td>\n",
       "      <td>2.450999</td>\n",
       "      <td>0.040986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>0.817686</td>\n",
       "      <td>0.815479</td>\n",
       "      <td>0.816583</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>8</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>0.817420</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.664007</td>\n",
       "      <td>1.899254e-02</td>\n",
       "      <td>4.747497</td>\n",
       "      <td>0.100513</td>\n",
       "      <td>0.5</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 600}</td>\n",
       "      <td>0.817029</td>\n",
       "      <td>0.815611</td>\n",
       "      <td>0.816320</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>9</td>\n",
       "      <td>0.815808</td>\n",
       "      <td>0.818047</td>\n",
       "      <td>0.816928</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.664502</td>\n",
       "      <td>3.550267e-02</td>\n",
       "      <td>0.772999</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>1.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 100}</td>\n",
       "      <td>0.816504</td>\n",
       "      <td>0.815840</td>\n",
       "      <td>0.816172</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.818737</td>\n",
       "      <td>0.816353</td>\n",
       "      <td>0.002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.094501</td>\n",
       "      <td>1.434788e-01</td>\n",
       "      <td>4.002991</td>\n",
       "      <td>0.032010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 500}</td>\n",
       "      <td>0.816405</td>\n",
       "      <td>0.814658</td>\n",
       "      <td>0.815531</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>11</td>\n",
       "      <td>0.814691</td>\n",
       "      <td>0.816996</td>\n",
       "      <td>0.815843</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.717999</td>\n",
       "      <td>6.300187e-02</td>\n",
       "      <td>1.659499</td>\n",
       "      <td>0.061499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>0.815617</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.814661</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>12</td>\n",
       "      <td>0.814132</td>\n",
       "      <td>0.816996</td>\n",
       "      <td>0.815564</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.381536</td>\n",
       "      <td>1.684840e-01</td>\n",
       "      <td>2.350479</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>0.813317</td>\n",
       "      <td>0.810650</td>\n",
       "      <td>0.811984</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>13</td>\n",
       "      <td>0.811044</td>\n",
       "      <td>0.814138</td>\n",
       "      <td>0.812591</td>\n",
       "      <td>0.001547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.319999</td>\n",
       "      <td>5.900002e-02</td>\n",
       "      <td>1.212008</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 150}</td>\n",
       "      <td>0.811313</td>\n",
       "      <td>0.809632</td>\n",
       "      <td>0.810473</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>14</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.812759</td>\n",
       "      <td>0.811113</td>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.807498</td>\n",
       "      <td>3.564813e-01</td>\n",
       "      <td>1.545493</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>0.809901</td>\n",
       "      <td>0.806774</td>\n",
       "      <td>0.808337</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>15</td>\n",
       "      <td>0.808581</td>\n",
       "      <td>0.810262</td>\n",
       "      <td>0.809421</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.409496</td>\n",
       "      <td>4.351044e-02</td>\n",
       "      <td>1.203499</td>\n",
       "      <td>0.064501</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 150}</td>\n",
       "      <td>0.805039</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.804362</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>16</td>\n",
       "      <td>0.801879</td>\n",
       "      <td>0.805860</td>\n",
       "      <td>0.803870</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.848001</td>\n",
       "      <td>4.800189e-02</td>\n",
       "      <td>0.826499</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>0.800210</td>\n",
       "      <td>0.801485</td>\n",
       "      <td>0.800848</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>17</td>\n",
       "      <td>0.798758</td>\n",
       "      <td>0.803495</td>\n",
       "      <td>0.801127</td>\n",
       "      <td>0.002368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.132498</td>\n",
       "      <td>7.050252e-02</td>\n",
       "      <td>0.861994</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.796235</td>\n",
       "      <td>0.793469</td>\n",
       "      <td>0.794852</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>18</td>\n",
       "      <td>0.793436</td>\n",
       "      <td>0.796564</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.001564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.090502</td>\n",
       "      <td>4.496574e-03</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.5</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 70}</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.784633</td>\n",
       "      <td>0.786443</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>19</td>\n",
       "      <td>0.785487</td>\n",
       "      <td>0.788384</td>\n",
       "      <td>0.786936</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.945994</td>\n",
       "      <td>1.037121e-05</td>\n",
       "      <td>0.540499</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>1.5</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 70}</td>\n",
       "      <td>0.787990</td>\n",
       "      <td>0.782202</td>\n",
       "      <td>0.785096</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>20</td>\n",
       "      <td>0.785322</td>\n",
       "      <td>0.783359</td>\n",
       "      <td>0.784340</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.964511</td>\n",
       "      <td>4.648840e-02</td>\n",
       "      <td>0.547488</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 70}</td>\n",
       "      <td>0.781322</td>\n",
       "      <td>0.786406</td>\n",
       "      <td>0.783864</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>21</td>\n",
       "      <td>0.780461</td>\n",
       "      <td>0.787695</td>\n",
       "      <td>0.784078</td>\n",
       "      <td>0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.097005</td>\n",
       "      <td>2.098930e-02</td>\n",
       "      <td>3.790486</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 500}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15.751002</td>\n",
       "      <td>8.699667e-02</td>\n",
       "      <td>4.524998</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>2.0</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 600}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.865997</td>\n",
       "      <td>9.974241e-04</td>\n",
       "      <td>2.255992</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 300}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.273011</td>\n",
       "      <td>1.098907e-02</td>\n",
       "      <td>1.513498</td>\n",
       "      <td>0.035497</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 200}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.077990</td>\n",
       "      <td>1.010418e-03</td>\n",
       "      <td>1.162518</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 150}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.679001</td>\n",
       "      <td>5.800092e-02</td>\n",
       "      <td>0.783992</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 100}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.861999</td>\n",
       "      <td>1.192093e-07</td>\n",
       "      <td>0.532992</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 70}</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>22</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.844987</td>\n",
       "      <td>9.298766e-02</td>\n",
       "      <td>2.883494</td>\n",
       "      <td>0.095492</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 300}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.641509</td>\n",
       "      <td>2.451444e-02</td>\n",
       "      <td>1.756489</td>\n",
       "      <td>0.065497</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 200}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.685010</td>\n",
       "      <td>7.996559e-03</td>\n",
       "      <td>1.316492</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 150}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.797025</td>\n",
       "      <td>1.702583e-02</td>\n",
       "      <td>0.833002</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 100}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.373011</td>\n",
       "      <td>1.298988e-02</td>\n",
       "      <td>0.636988</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 70}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9.183992</td>\n",
       "      <td>9.530075e-01</td>\n",
       "      <td>4.664711</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>10.0</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 500}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10.086500</td>\n",
       "      <td>6.649959e-02</td>\n",
       "      <td>4.725000</td>\n",
       "      <td>0.130999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 10.0, 'n_estimators': 600}</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>29</td>\n",
       "      <td>0.500214</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>0.500222</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.278492</td>\n",
       "      <td>6.649256e-02</td>\n",
       "      <td>0.565508</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 70}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15.240502</td>\n",
       "      <td>1.880498e+00</td>\n",
       "      <td>4.462990</td>\n",
       "      <td>0.617995</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 500}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.509992</td>\n",
       "      <td>4.099190e-02</td>\n",
       "      <td>1.156003</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 150}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.268002</td>\n",
       "      <td>1.498127e-02</td>\n",
       "      <td>1.559001</td>\n",
       "      <td>0.050979</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 200}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.874990</td>\n",
       "      <td>2.589874e-01</td>\n",
       "      <td>2.614510</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 300}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.094418</td>\n",
       "      <td>7.042265e-02</td>\n",
       "      <td>4.405999</td>\n",
       "      <td>0.212999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 500}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.779516</td>\n",
       "      <td>2.624844e-01</td>\n",
       "      <td>5.481511</td>\n",
       "      <td>0.445491</td>\n",
       "      <td>5.0</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 600}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.990016</td>\n",
       "      <td>4.500008e-02</td>\n",
       "      <td>2.306002</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 300}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.314983</td>\n",
       "      <td>1.399934e-02</td>\n",
       "      <td>1.539519</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 200}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.021502</td>\n",
       "      <td>1.150095e-02</td>\n",
       "      <td>1.157998</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 150}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.672492</td>\n",
       "      <td>3.487706e-03</td>\n",
       "      <td>0.761998</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 100}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.864343</td>\n",
       "      <td>5.359769e-03</td>\n",
       "      <td>0.532001</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 70}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18.814503</td>\n",
       "      <td>1.378498e+00</td>\n",
       "      <td>5.189488</td>\n",
       "      <td>0.292509</td>\n",
       "      <td>3.0</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 3.0, 'n_estimators': 600}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.721001</td>\n",
       "      <td>3.400660e-02</td>\n",
       "      <td>0.772488</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 5.0, 'n_estimators': 100}</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>36</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>0.437905</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "17       5.521178  1.588398e-01         1.555501        0.052497   \n",
       "18       8.054733  1.282513e-01         2.292000        0.009001   \n",
       "13      16.096500  3.765002e-01         4.601483        0.114499   \n",
       "12      14.478000  2.290028e-01         4.492502        0.145502   \n",
       "16       3.951005  6.437302e-06         1.111511        0.002489   \n",
       "19      13.603209  3.968124e-01         3.716492        0.015492   \n",
       "20      15.790011  6.699562e-02         4.536492        0.016492   \n",
       "11       8.399500  6.149924e-02         2.450999        0.040986   \n",
       "6       16.664007  1.899254e-02         4.747497        0.100513   \n",
       "15       2.664502  3.550267e-02         0.772999        0.017004   \n",
       "5       14.094501  1.434788e-01         4.002991        0.032010   \n",
       "10       5.717999  6.300187e-02         1.659499        0.061499   \n",
       "4        8.381536  1.684840e-01         2.350479        0.008500   \n",
       "9        4.319999  5.900002e-02         1.212008        0.013991   \n",
       "3        5.807498  3.564813e-01         1.545493        0.002506   \n",
       "2        4.409496  4.351044e-02         1.203499        0.064501   \n",
       "8        2.848001  4.800189e-02         0.826499        0.022500   \n",
       "1        3.132498  7.050252e-02         0.861994        0.000993   \n",
       "0        2.090502  4.496574e-03         0.600011        0.018989   \n",
       "14       1.945994  1.037121e-05         0.540499        0.011497   \n",
       "7        1.964511  4.648840e-02         0.547488        0.005488   \n",
       "26      13.097005  2.098930e-02         3.790486        0.003500   \n",
       "27      15.751002  8.699667e-02         4.524998        0.007997   \n",
       "25       7.865997  9.974241e-04         2.255992        0.041992   \n",
       "24       5.273011  1.098907e-02         1.513498        0.035497   \n",
       "23       4.077990  1.010418e-03         1.162518        0.018498   \n",
       "22       2.679001  5.800092e-02         0.783992        0.031007   \n",
       "21       1.861999  1.192093e-07         0.532992        0.001993   \n",
       "46       5.844987  9.298766e-02         2.883494        0.095492   \n",
       "45       3.641509  2.451444e-02         1.756489        0.065497   \n",
       "44       2.685010  7.996559e-03         1.316492        0.002507   \n",
       "43       1.797025  1.702583e-02         0.833002        0.005019   \n",
       "42       1.373011  1.298988e-02         0.636988        0.001991   \n",
       "47       9.183992  9.530075e-01         4.664711        0.010309   \n",
       "48      10.086500  6.649959e-02         4.725000        0.130999   \n",
       "35       1.278492  6.649256e-02         0.565508        0.019507   \n",
       "33      15.240502  1.880498e+00         4.462990        0.617995   \n",
       "37       2.509992  4.099190e-02         1.156003        0.008982   \n",
       "38       3.268002  1.498127e-02         1.559001        0.050979   \n",
       "39       5.874990  2.589874e-01         2.614510        0.026509   \n",
       "40       9.094418  7.042265e-02         4.405999        0.212999   \n",
       "41      10.779516  2.624844e-01         5.481511        0.445491   \n",
       "32       7.990016  4.500008e-02         2.306002        0.020003   \n",
       "31       5.314983  1.399934e-02         1.539519        0.004497   \n",
       "30       4.021502  1.150095e-02         1.157998        0.015001   \n",
       "29       2.672492  3.487706e-03         0.761998        0.002981   \n",
       "28       1.864343  5.359769e-03         0.532001        0.002000   \n",
       "34      18.814503  1.378498e+00         5.189488        0.292509   \n",
       "36       1.721001  3.400660e-02         0.772488        0.017502   \n",
       "\n",
       "   param_learning_rate param_n_estimators  \\\n",
       "17                 1.5                200   \n",
       "18                 1.5                300   \n",
       "13                 1.0                600   \n",
       "12                 1.0                500   \n",
       "16                 1.5                150   \n",
       "19                 1.5                500   \n",
       "20                 1.5                600   \n",
       "11                 1.0                300   \n",
       "6                  0.5                600   \n",
       "15                 1.5                100   \n",
       "5                  0.5                500   \n",
       "10                 1.0                200   \n",
       "4                  0.5                300   \n",
       "9                  1.0                150   \n",
       "3                  0.5                200   \n",
       "2                  0.5                150   \n",
       "8                  1.0                100   \n",
       "1                  0.5                100   \n",
       "0                  0.5                 70   \n",
       "14                 1.5                 70   \n",
       "7                  1.0                 70   \n",
       "26                 2.0                500   \n",
       "27                 2.0                600   \n",
       "25                 2.0                300   \n",
       "24                 2.0                200   \n",
       "23                 2.0                150   \n",
       "22                 2.0                100   \n",
       "21                 2.0                 70   \n",
       "46                10.0                300   \n",
       "45                10.0                200   \n",
       "44                10.0                150   \n",
       "43                10.0                100   \n",
       "42                10.0                 70   \n",
       "47                10.0                500   \n",
       "48                10.0                600   \n",
       "35                 5.0                 70   \n",
       "33                 3.0                500   \n",
       "37                 5.0                150   \n",
       "38                 5.0                200   \n",
       "39                 5.0                300   \n",
       "40                 5.0                500   \n",
       "41                 5.0                600   \n",
       "32                 3.0                300   \n",
       "31                 3.0                200   \n",
       "30                 3.0                150   \n",
       "29                 3.0                100   \n",
       "28                 3.0                 70   \n",
       "34                 3.0                600   \n",
       "36                 5.0                100   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "17   {'learning_rate': 1.5, 'n_estimators': 200}           0.819066   \n",
       "18   {'learning_rate': 1.5, 'n_estimators': 300}           0.818770   \n",
       "13   {'learning_rate': 1.0, 'n_estimators': 600}           0.818573   \n",
       "12   {'learning_rate': 1.0, 'n_estimators': 500}           0.818474   \n",
       "16   {'learning_rate': 1.5, 'n_estimators': 150}           0.818836   \n",
       "19   {'learning_rate': 1.5, 'n_estimators': 500}           0.818442   \n",
       "20   {'learning_rate': 1.5, 'n_estimators': 600}           0.818376   \n",
       "11   {'learning_rate': 1.0, 'n_estimators': 300}           0.817686   \n",
       "6    {'learning_rate': 0.5, 'n_estimators': 600}           0.817029   \n",
       "15   {'learning_rate': 1.5, 'n_estimators': 100}           0.816504   \n",
       "5    {'learning_rate': 0.5, 'n_estimators': 500}           0.816405   \n",
       "10   {'learning_rate': 1.0, 'n_estimators': 200}           0.815617   \n",
       "4    {'learning_rate': 0.5, 'n_estimators': 300}           0.813317   \n",
       "9    {'learning_rate': 1.0, 'n_estimators': 150}           0.811313   \n",
       "3    {'learning_rate': 0.5, 'n_estimators': 200}           0.809901   \n",
       "2    {'learning_rate': 0.5, 'n_estimators': 150}           0.805039   \n",
       "8    {'learning_rate': 1.0, 'n_estimators': 100}           0.800210   \n",
       "1    {'learning_rate': 0.5, 'n_estimators': 100}           0.796235   \n",
       "0     {'learning_rate': 0.5, 'n_estimators': 70}           0.788253   \n",
       "14    {'learning_rate': 1.5, 'n_estimators': 70}           0.787990   \n",
       "7     {'learning_rate': 1.0, 'n_estimators': 70}           0.781322   \n",
       "26   {'learning_rate': 2.0, 'n_estimators': 500}           0.612148   \n",
       "27   {'learning_rate': 2.0, 'n_estimators': 600}           0.612148   \n",
       "25   {'learning_rate': 2.0, 'n_estimators': 300}           0.612148   \n",
       "24   {'learning_rate': 2.0, 'n_estimators': 200}           0.612148   \n",
       "23   {'learning_rate': 2.0, 'n_estimators': 150}           0.612148   \n",
       "22   {'learning_rate': 2.0, 'n_estimators': 100}           0.612148   \n",
       "21    {'learning_rate': 2.0, 'n_estimators': 70}           0.612148   \n",
       "46  {'learning_rate': 10.0, 'n_estimators': 300}           0.500230   \n",
       "45  {'learning_rate': 10.0, 'n_estimators': 200}           0.500230   \n",
       "44  {'learning_rate': 10.0, 'n_estimators': 150}           0.500230   \n",
       "43  {'learning_rate': 10.0, 'n_estimators': 100}           0.500230   \n",
       "42   {'learning_rate': 10.0, 'n_estimators': 70}           0.500230   \n",
       "47  {'learning_rate': 10.0, 'n_estimators': 500}           0.500230   \n",
       "48  {'learning_rate': 10.0, 'n_estimators': 600}           0.500230   \n",
       "35    {'learning_rate': 5.0, 'n_estimators': 70}           0.438079   \n",
       "33   {'learning_rate': 3.0, 'n_estimators': 500}           0.438079   \n",
       "37   {'learning_rate': 5.0, 'n_estimators': 150}           0.438079   \n",
       "38   {'learning_rate': 5.0, 'n_estimators': 200}           0.438079   \n",
       "39   {'learning_rate': 5.0, 'n_estimators': 300}           0.438079   \n",
       "40   {'learning_rate': 5.0, 'n_estimators': 500}           0.438079   \n",
       "41   {'learning_rate': 5.0, 'n_estimators': 600}           0.438079   \n",
       "32   {'learning_rate': 3.0, 'n_estimators': 300}           0.438079   \n",
       "31   {'learning_rate': 3.0, 'n_estimators': 200}           0.438079   \n",
       "30   {'learning_rate': 3.0, 'n_estimators': 150}           0.438079   \n",
       "29   {'learning_rate': 3.0, 'n_estimators': 100}           0.438079   \n",
       "28    {'learning_rate': 3.0, 'n_estimators': 70}           0.438079   \n",
       "34   {'learning_rate': 3.0, 'n_estimators': 600}           0.438079   \n",
       "36   {'learning_rate': 5.0, 'n_estimators': 100}           0.438079   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "17           0.816563         0.817814        0.001251                1   \n",
       "18           0.816662         0.817716        0.001054                2   \n",
       "13           0.816662         0.817617        0.000956                3   \n",
       "12           0.816629         0.817552        0.000923                4   \n",
       "16           0.815840         0.817338        0.001498                5   \n",
       "19           0.816136         0.817289        0.001153                6   \n",
       "20           0.815972         0.817174        0.001202                7   \n",
       "11           0.815479         0.816583        0.001103                8   \n",
       "6            0.815611         0.816320        0.000709                9   \n",
       "15           0.815840         0.816172        0.000332               10   \n",
       "5            0.814658         0.815531        0.000874               11   \n",
       "10           0.813705         0.814661        0.000956               12   \n",
       "4            0.810650         0.811984        0.001334               13   \n",
       "9            0.809632         0.810473        0.000841               14   \n",
       "3            0.806774         0.808337        0.001564               15   \n",
       "2            0.803686         0.804362        0.000677               16   \n",
       "8            0.801485         0.800848        0.000637               17   \n",
       "1            0.793469         0.794852        0.001383               18   \n",
       "0            0.784633         0.786443        0.001810               19   \n",
       "14           0.782202         0.785096        0.002894               20   \n",
       "7            0.786406         0.783864        0.002542               21   \n",
       "26           0.614434         0.613291        0.001143               22   \n",
       "27           0.614434         0.613291        0.001143               22   \n",
       "25           0.614434         0.613291        0.001143               22   \n",
       "24           0.614434         0.613291        0.001143               22   \n",
       "23           0.614434         0.613291        0.001143               22   \n",
       "22           0.614434         0.613291        0.001143               22   \n",
       "21           0.614434         0.613291        0.001143               22   \n",
       "46           0.500214         0.500222        0.000008               29   \n",
       "45           0.500214         0.500222        0.000008               29   \n",
       "44           0.500214         0.500222        0.000008               29   \n",
       "43           0.500214         0.500222        0.000008               29   \n",
       "42           0.500214         0.500222        0.000008               29   \n",
       "47           0.500214         0.500222        0.000008               29   \n",
       "48           0.500214         0.500222        0.000008               29   \n",
       "35           0.437732         0.437905        0.000173               36   \n",
       "33           0.437732         0.437905        0.000173               36   \n",
       "37           0.437732         0.437905        0.000173               36   \n",
       "38           0.437732         0.437905        0.000173               36   \n",
       "39           0.437732         0.437905        0.000173               36   \n",
       "40           0.437732         0.437905        0.000173               36   \n",
       "41           0.437732         0.437905        0.000173               36   \n",
       "32           0.437732         0.437905        0.000173               36   \n",
       "31           0.437732         0.437905        0.000173               36   \n",
       "30           0.437732         0.437905        0.000173               36   \n",
       "29           0.437732         0.437905        0.000173               36   \n",
       "28           0.437732         0.437905        0.000173               36   \n",
       "34           0.437732         0.437905        0.000173               36   \n",
       "36           0.437732         0.437905        0.000173               36   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "17            0.817220            0.819099          0.818159         0.000939  \n",
       "18            0.817614            0.819296          0.818455         0.000841  \n",
       "13            0.817713            0.819986          0.818849         0.001136  \n",
       "12            0.817647            0.819427          0.818537         0.000890  \n",
       "16            0.816662            0.819263          0.817962         0.001301  \n",
       "19            0.817943            0.819131          0.818537         0.000594  \n",
       "20            0.817812            0.819131          0.818471         0.000660  \n",
       "11            0.816925            0.817916          0.817420         0.000496  \n",
       "6             0.815808            0.818047          0.816928         0.001120  \n",
       "15            0.813968            0.818737          0.816353         0.002385  \n",
       "5             0.814691            0.816996          0.815843         0.001153  \n",
       "10            0.814132            0.816996          0.815564         0.001432  \n",
       "4             0.811044            0.814138          0.812591         0.001547  \n",
       "9             0.809467            0.812759          0.811113         0.001646  \n",
       "3             0.808581            0.810262          0.809421         0.000841  \n",
       "2             0.801879            0.805860          0.803870         0.001991  \n",
       "8             0.798758            0.803495          0.801127         0.002368  \n",
       "1             0.793436            0.796564          0.795000         0.001564  \n",
       "0             0.785487            0.788384          0.786936         0.001449  \n",
       "14            0.785322            0.783359          0.784340         0.000982  \n",
       "7             0.780461            0.787695          0.784078         0.003617  \n",
       "26            0.614434            0.612148          0.613291         0.001143  \n",
       "27            0.614434            0.612148          0.613291         0.001143  \n",
       "25            0.614434            0.612148          0.613291         0.001143  \n",
       "24            0.614434            0.612148          0.613291         0.001143  \n",
       "23            0.614434            0.612148          0.613291         0.001143  \n",
       "22            0.614434            0.612148          0.613291         0.001143  \n",
       "21            0.614434            0.612148          0.613291         0.001143  \n",
       "46            0.500214            0.500230          0.500222         0.000008  \n",
       "45            0.500214            0.500230          0.500222         0.000008  \n",
       "44            0.500214            0.500230          0.500222         0.000008  \n",
       "43            0.500214            0.500230          0.500222         0.000008  \n",
       "42            0.500214            0.500230          0.500222         0.000008  \n",
       "47            0.500214            0.500230          0.500222         0.000008  \n",
       "48            0.500214            0.500230          0.500222         0.000008  \n",
       "35            0.437732            0.438079          0.437905         0.000173  \n",
       "33            0.437732            0.438079          0.437905         0.000173  \n",
       "37            0.437732            0.438079          0.437905         0.000173  \n",
       "38            0.437732            0.438079          0.437905         0.000173  \n",
       "39            0.437732            0.438079          0.437905         0.000173  \n",
       "40            0.437732            0.438079          0.437905         0.000173  \n",
       "41            0.437732            0.438079          0.437905         0.000173  \n",
       "32            0.437732            0.438079          0.437905         0.000173  \n",
       "31            0.437732            0.438079          0.437905         0.000173  \n",
       "30            0.437732            0.438079          0.437905         0.000173  \n",
       "29            0.437732            0.438079          0.437905         0.000173  \n",
       "28            0.437732            0.438079          0.437905         0.000173  \n",
       "34            0.437732            0.438079          0.437905         0.000173  \n",
       "36            0.437732            0.438079          0.437905         0.000173  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada3.sort_values(by=['rank_test_score'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5924016b-9272-418e-87ab-2bf06b9c1795",
   "metadata": {},
   "source": [
    "best = gridDecisionTree.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567da5ef-a57e-42e7-8499-74fad0c783fc",
   "metadata": {},
   "source": [
    "best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8bc3c-ad90-46b7-8cc8-dd10d40fdd33",
   "metadata": {},
   "source": [
    "teste = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45206ff-d40c-4570-8915-715e778fd23e",
   "metadata": {},
   "source": [
    "print(classification_report(y_test, teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00022c-055e-4f19-aa6f-4aaaa62d0a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34912a3-0298-47e1-8ec7-64c4e1eb0f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deca88ed-640c-4c08-bff2-184c57ff84ff",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "6918c0b4-4ad1-493a-9001-19a68777a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(criterion='gini',\n",
    "                                 max_leaf_nodes=None,\n",
    "                                 bootstrap=True,\n",
    "                                 oob_score=True,\n",
    "                                 n_jobs = -1)\n",
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9e5aa84e-291b-4732-be90-13dfa81a649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search parameters\n",
    "n_estimators = np.array([1000,2000])\n",
    "max_depth = np.array([15,50,None])\n",
    "values_grid_forest = {'n_estimators': n_estimators, 'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6929ee28-267e-48e1-beac-39f1c0ba3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END ...max_depth=15, n_estimators=1000;, score=0.698 total time=  17.7s\n",
      "[CV 2/2] END ...max_depth=15, n_estimators=1000;, score=0.704 total time=  16.3s\n",
      "[CV 1/2] END ...max_depth=15, n_estimators=2000;, score=0.698 total time=  35.8s\n",
      "[CV 2/2] END ...max_depth=15, n_estimators=2000;, score=0.704 total time=  34.5s\n",
      "[CV 1/2] END ...max_depth=50, n_estimators=1000;, score=0.780 total time=  28.3s\n",
      "[CV 2/2] END ...max_depth=50, n_estimators=1000;, score=0.782 total time=  30.2s\n",
      "[CV 1/2] END ...max_depth=50, n_estimators=2000;, score=0.778 total time= 1.0min\n",
      "[CV 2/2] END ...max_depth=50, n_estimators=2000;, score=0.781 total time= 1.1min\n",
      "[CV 1/2] END .max_depth=None, n_estimators=1000;, score=0.780 total time=  31.5s\n",
      "[CV 2/2] END .max_depth=None, n_estimators=1000;, score=0.779 total time=  30.0s\n",
      "[CV 1/2] END .max_depth=None, n_estimators=2000;, score=0.779 total time=  56.5s\n",
      "[CV 2/2] END .max_depth=None, n_estimators=2000;, score=0.781 total time=  57.1s\n"
     ]
    }
   ],
   "source": [
    "#Using grid search to find the best values\n",
    "gridForest = GridSearchCV(estimator = rand_forest,\n",
    "                                param_grid = values_grid_forest,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1)\n",
    "gridForest.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b005f-2877-4098-abd2-95c1d19702d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187ffdb-9827-4b46-b631-4032e1a0eafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11a359-1e5f-41fd-9942-736db239bf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4012f0d-6dde-477a-af85-f5166b81e12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee862c-0cff-4c20-a9b2-b356459045da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74493ebc-daa9-4e9e-8e05-de5980f886d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac993a-b133-44fe-8988-8e956bc55560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "566d6104-747f-4e51-94ef-9ff24b837e47",
   "metadata": {},
   "source": [
    "# SAGEMAKER TIMEOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "931b9178-75f8-4924-abd0-eeae9fa87f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the classifier\n",
    "extra_tree = ExtraTreesClassifier(n_estimators=1000, random_state=1216, n_jobs = -1)\n",
    "X, y = df_splitter(datasets['oversampled-'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3612c13a-d0e9-4f93-8a6f-886502df29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the parameters for the grid search\n",
    "min_samples_split = np.array([2,10,40])\n",
    "max_depth = np.array([50])\n",
    "max_leaf_nodes = np.array([5,20,None])\n",
    "values_grid = {'min_samples_split': min_samples_split,\n",
    "               'max_depth': max_depth,\n",
    "               'max_leaf_nodes':max_leaf_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "81873337-102b-48f0-aa0a-944f61b62373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=2;, score=0.560 total time=   4.6s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=2;, score=0.565 total time=   3.2s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=10;, score=0.560 total time=   3.7s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=10;, score=0.565 total time=   3.2s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=40;, score=0.559 total time=   3.1s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=5, min_samples_split=40;, score=0.565 total time=   3.2s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=2;, score=0.573 total time=   4.5s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=2;, score=0.577 total time=   4.2s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=10;, score=0.572 total time=   4.5s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=10;, score=0.576 total time=   4.1s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=40;, score=0.573 total time=   4.5s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=20, min_samples_split=40;, score=0.577 total time=   5.0s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=2;, score=0.778 total time=  26.8s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=2;, score=0.776 total time=  27.1s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=10;, score=0.738 total time=  20.1s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=10;, score=0.740 total time=  18.7s\n",
      "[CV 1/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=40;, score=0.674 total time=  13.3s\n",
      "[CV 2/2] END max_depth=50, max_leaf_nodes=None, min_samples_split=40;, score=0.677 total time=  14.6s\n"
     ]
    }
   ],
   "source": [
    "#Using grid search to find the best values\n",
    "gridExtraTrees = GridSearchCV(estimator = extra_tree,\n",
    "                                param_grid = values_grid,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1)\n",
    "gridExtraTrees.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90be6db7-3ae6-43d6-9dd1-26df49da0199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.116010</td>\n",
       "      <td>0.803992</td>\n",
       "      <td>3.258242</td>\n",
       "      <td>0.350760</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.778990</td>\n",
       "      <td>0.777570</td>\n",
       "      <td>0.778280</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27.047147</td>\n",
       "      <td>2.132966</td>\n",
       "      <td>3.683592</td>\n",
       "      <td>0.223590</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': None, 'mi...</td>\n",
       "      <td>0.778563</td>\n",
       "      <td>0.777898</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21.062875</td>\n",
       "      <td>0.510874</td>\n",
       "      <td>3.192063</td>\n",
       "      <td>0.123935</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': None, 'm...</td>\n",
       "      <td>0.778563</td>\n",
       "      <td>0.777898</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.963256</td>\n",
       "      <td>0.129254</td>\n",
       "      <td>2.354501</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.734380</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.736692</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15.457785</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>2.746001</td>\n",
       "      <td>0.108001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': None, 'm...</td>\n",
       "      <td>0.734183</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.736593</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.766568</td>\n",
       "      <td>1.280484</td>\n",
       "      <td>2.620498</td>\n",
       "      <td>0.131499</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': None, 'mi...</td>\n",
       "      <td>0.734183</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.736593</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.242273</td>\n",
       "      <td>0.178831</td>\n",
       "      <td>1.978014</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': None, 'mi...</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.674978</td>\n",
       "      <td>0.673456</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.022001</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>2.425501</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.674978</td>\n",
       "      <td>0.673456</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11.120499</td>\n",
       "      <td>0.167501</td>\n",
       "      <td>2.210259</td>\n",
       "      <td>0.207256</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': None, 'm...</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.674978</td>\n",
       "      <td>0.673456</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.031060</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>1.182779</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.618586</td>\n",
       "      <td>0.609178</td>\n",
       "      <td>0.613882</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.679913</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>1.284417</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.610177</td>\n",
       "      <td>0.600900</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.635491</td>\n",
       "      <td>0.052798</td>\n",
       "      <td>1.386406</td>\n",
       "      <td>0.178429</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': None, 'min...</td>\n",
       "      <td>0.600158</td>\n",
       "      <td>0.593049</td>\n",
       "      <td>0.596603</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.595499</td>\n",
       "      <td>0.123502</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.081499</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 20, 'min...</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.572977</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.689395</td>\n",
       "      <td>0.042372</td>\n",
       "      <td>0.822141</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.572977</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.604758</td>\n",
       "      <td>0.705760</td>\n",
       "      <td>0.963499</td>\n",
       "      <td>0.032499</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 20, 'min_...</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.572977</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.014587</td>\n",
       "      <td>0.427667</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579134</td>\n",
       "      <td>0.573798</td>\n",
       "      <td>0.576466</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.599580</td>\n",
       "      <td>0.043581</td>\n",
       "      <td>0.775989</td>\n",
       "      <td>0.034991</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 20, 'min...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.624501</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>1.083019</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 20, 'min_...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.896329</td>\n",
       "      <td>0.278227</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.656427</td>\n",
       "      <td>0.083573</td>\n",
       "      <td>0.780757</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579463</td>\n",
       "      <td>0.573404</td>\n",
       "      <td>0.576433</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.426500</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.754500</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 20, 'min...</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.572846</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.649449</td>\n",
       "      <td>0.303433</td>\n",
       "      <td>0.852856</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.572846</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.058906</td>\n",
       "      <td>0.095832</td>\n",
       "      <td>0.921818</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 20, 'min_...</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.572846</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.811754</td>\n",
       "      <td>0.061141</td>\n",
       "      <td>0.845649</td>\n",
       "      <td>0.064309</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...</td>\n",
       "      <td>0.579725</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.575974</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.544479</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.619092</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 5, 'min_...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.631931</td>\n",
       "      <td>0.806068</td>\n",
       "      <td>0.706461</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.627601</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.708193</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.061685</td>\n",
       "      <td>0.466333</td>\n",
       "      <td>0.713355</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.559049</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.141531</td>\n",
       "      <td>0.108468</td>\n",
       "      <td>0.738698</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.758005</td>\n",
       "      <td>0.142093</td>\n",
       "      <td>0.667414</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 5, 'min_...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.784822</td>\n",
       "      <td>0.041058</td>\n",
       "      <td>0.724589</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.677874</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>0.664848</td>\n",
       "      <td>0.026796</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568130</td>\n",
       "      <td>0.559016</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.512624</td>\n",
       "      <td>0.078098</td>\n",
       "      <td>0.684490</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.488943</td>\n",
       "      <td>0.051059</td>\n",
       "      <td>0.653055</td>\n",
       "      <td>0.010942</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'max_leaf_nodes': 5, 'min_...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.847042</td>\n",
       "      <td>0.121930</td>\n",
       "      <td>0.711627</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.989347</td>\n",
       "      <td>0.243851</td>\n",
       "      <td>0.719810</td>\n",
       "      <td>0.010864</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15      22.116010      0.803992         3.258242        0.350760   \n",
       "24      27.047147      2.132966         3.683592        0.223590   \n",
       "33      21.062875      0.510874         3.192063        0.123935   \n",
       "16      13.963256      0.129254         2.354501        0.026500   \n",
       "34      15.457785      0.242784         2.746001        0.108001   \n",
       "25      16.766568      1.280484         2.620498        0.131499   \n",
       "26      10.242273      0.178831         1.978014        0.090016   \n",
       "17      12.022001      0.039999         2.425501        0.307500   \n",
       "35      11.120499      0.167501         2.210259        0.207256   \n",
       "6        6.031060      0.118056         1.182779        0.000781   \n",
       "7        6.679913      0.014798         1.284417        0.041253   \n",
       "8        6.635491      0.052798         1.386406        0.178429   \n",
       "31       3.595499      0.123502         0.792500        0.081499   \n",
       "13       3.689395      0.042372         0.822141        0.001074   \n",
       "22       4.604758      0.705760         0.963499        0.032499   \n",
       "4        4.014587      0.427667         0.765794        0.018270   \n",
       "30       3.599580      0.043581         0.775989        0.034991   \n",
       "21       4.624501      0.211500         1.083019        0.085020   \n",
       "12       3.896329      0.278227         0.839799        0.100429   \n",
       "3        3.656427      0.083573         0.780757        0.054242   \n",
       "32       3.426500      0.102500         0.754500        0.002499   \n",
       "14       3.649449      0.303433         0.852856        0.013126   \n",
       "23       4.058906      0.095832         0.921818        0.002820   \n",
       "5        3.811754      0.061141         0.845649        0.064309   \n",
       "27       2.544479      0.109792         0.619092        0.000191   \n",
       "0        3.631931      0.806068         0.706461        0.006537   \n",
       "9        2.627601      0.013492         0.708193        0.032202   \n",
       "18       3.061685      0.466333         0.713355        0.029593   \n",
       "20       3.141531      0.108468         0.738698        0.091300   \n",
       "29       2.758005      0.142093         0.667414        0.006416   \n",
       "11       2.784822      0.041058         0.724589        0.094406   \n",
       "2        2.677874      0.052096         0.664848        0.026796   \n",
       "19       2.512624      0.078098         0.684490        0.001506   \n",
       "28       2.488943      0.051059         0.653055        0.010942   \n",
       "1        2.847042      0.121930         0.711627        0.022373   \n",
       "10       2.989347      0.243851         0.719810        0.010864   \n",
       "\n",
       "   param_max_depth param_max_leaf_nodes param_min_samples_split  \\\n",
       "15              50                 None                       2   \n",
       "24             100                 None                       2   \n",
       "33            None                 None                       2   \n",
       "16              50                 None                      10   \n",
       "34            None                 None                      10   \n",
       "25             100                 None                      10   \n",
       "26             100                 None                      40   \n",
       "17              50                 None                      40   \n",
       "35            None                 None                      40   \n",
       "6               10                 None                       2   \n",
       "7               10                 None                      10   \n",
       "8               10                 None                      40   \n",
       "31            None                   20                      10   \n",
       "13              50                   20                      10   \n",
       "22             100                   20                      10   \n",
       "4               10                   20                      10   \n",
       "30            None                   20                       2   \n",
       "21             100                   20                       2   \n",
       "12              50                   20                       2   \n",
       "3               10                   20                       2   \n",
       "32            None                   20                      40   \n",
       "14              50                   20                      40   \n",
       "23             100                   20                      40   \n",
       "5               10                   20                      40   \n",
       "27            None                    5                       2   \n",
       "0               10                    5                       2   \n",
       "9               50                    5                       2   \n",
       "18             100                    5                       2   \n",
       "20             100                    5                      40   \n",
       "29            None                    5                      40   \n",
       "11              50                    5                      40   \n",
       "2               10                    5                      40   \n",
       "19             100                    5                      10   \n",
       "28            None                    5                      10   \n",
       "1               10                    5                      10   \n",
       "10              50                    5                      10   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'max_depth': 50, 'max_leaf_nodes': None, 'min...           0.778990   \n",
       "24  {'max_depth': 100, 'max_leaf_nodes': None, 'mi...           0.778563   \n",
       "33  {'max_depth': None, 'max_leaf_nodes': None, 'm...           0.778563   \n",
       "16  {'max_depth': 50, 'max_leaf_nodes': None, 'min...           0.734380   \n",
       "34  {'max_depth': None, 'max_leaf_nodes': None, 'm...           0.734183   \n",
       "25  {'max_depth': 100, 'max_leaf_nodes': None, 'mi...           0.734183   \n",
       "26  {'max_depth': 100, 'max_leaf_nodes': None, 'mi...           0.671934   \n",
       "17  {'max_depth': 50, 'max_leaf_nodes': None, 'min...           0.671934   \n",
       "35  {'max_depth': None, 'max_leaf_nodes': None, 'm...           0.671934   \n",
       "6   {'max_depth': 10, 'max_leaf_nodes': None, 'min...           0.618586   \n",
       "7   {'max_depth': 10, 'max_leaf_nodes': None, 'min...           0.610177   \n",
       "8   {'max_depth': 10, 'max_leaf_nodes': None, 'min...           0.600158   \n",
       "31  {'max_depth': None, 'max_leaf_nodes': 20, 'min...           0.579988   \n",
       "13  {'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...           0.579988   \n",
       "22  {'max_depth': 100, 'max_leaf_nodes': 20, 'min_...           0.579988   \n",
       "4   {'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...           0.579134   \n",
       "30  {'max_depth': None, 'max_leaf_nodes': 20, 'min...           0.579890   \n",
       "21  {'max_depth': 100, 'max_leaf_nodes': 20, 'min_...           0.579890   \n",
       "12  {'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...           0.579890   \n",
       "3   {'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...           0.579463   \n",
       "32  {'max_depth': None, 'max_leaf_nodes': 20, 'min...           0.579528   \n",
       "14  {'max_depth': 50, 'max_leaf_nodes': 20, 'min_s...           0.579528   \n",
       "23  {'max_depth': 100, 'max_leaf_nodes': 20, 'min_...           0.579528   \n",
       "5   {'max_depth': 10, 'max_leaf_nodes': 20, 'min_s...           0.579725   \n",
       "27  {'max_depth': None, 'max_leaf_nodes': 5, 'min_...           0.568261   \n",
       "0   {'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "9   {'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "18  {'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...           0.568261   \n",
       "20  {'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...           0.568130   \n",
       "29  {'max_depth': None, 'max_leaf_nodes': 5, 'min_...           0.568130   \n",
       "11  {'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...           0.568130   \n",
       "2   {'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...           0.568130   \n",
       "19  {'max_depth': 100, 'max_leaf_nodes': 5, 'min_s...           0.568261   \n",
       "28  {'max_depth': None, 'max_leaf_nodes': 5, 'min_...           0.568261   \n",
       "1   {'max_depth': 10, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "10  {'max_depth': 50, 'max_leaf_nodes': 5, 'min_sa...           0.568261   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.777570         0.778280        0.000710                1  \n",
       "24           0.777898         0.778230        0.000332                2  \n",
       "33           0.777898         0.778230        0.000332                2  \n",
       "16           0.739003         0.736692        0.002312                4  \n",
       "34           0.739003         0.736593        0.002410                5  \n",
       "25           0.739003         0.736593        0.002410                5  \n",
       "26           0.674978         0.673456        0.001522                7  \n",
       "17           0.674978         0.673456        0.001522                7  \n",
       "35           0.674978         0.673456        0.001522                7  \n",
       "6            0.609178         0.613882        0.004704               10  \n",
       "7            0.600900         0.605538        0.004638               11  \n",
       "8            0.593049         0.596603        0.003554               12  \n",
       "31           0.572977         0.576483        0.003505               13  \n",
       "13           0.572977         0.576483        0.003505               13  \n",
       "22           0.572977         0.576483        0.003505               13  \n",
       "4            0.573798         0.576466        0.002668               16  \n",
       "30           0.573010         0.576450        0.003440               17  \n",
       "21           0.573010         0.576450        0.003440               17  \n",
       "12           0.573010         0.576450        0.003440               17  \n",
       "3            0.573404         0.576433        0.003029               20  \n",
       "32           0.572846         0.576187        0.003341               21  \n",
       "14           0.572846         0.576187        0.003341               21  \n",
       "23           0.572846         0.576187        0.003341               21  \n",
       "5            0.572222         0.575974        0.003752               24  \n",
       "27           0.559049         0.563655        0.004606               25  \n",
       "0            0.559049         0.563655        0.004606               25  \n",
       "9            0.559049         0.563655        0.004606               25  \n",
       "18           0.559049         0.563655        0.004606               25  \n",
       "20           0.559016         0.563573        0.004557               29  \n",
       "29           0.559016         0.563573        0.004557               29  \n",
       "11           0.559016         0.563573        0.004557               29  \n",
       "2            0.559016         0.563573        0.004557               29  \n",
       "19           0.558884         0.563573        0.004688               33  \n",
       "28           0.558884         0.563573        0.004688               33  \n",
       "1            0.558884         0.563573        0.004688               33  \n",
       "10           0.558884         0.563573        0.004688               33  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_results = pd.DataFrame(gridExtraTrees.cv_results_)\n",
    "extra_trees_results.sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09509d16-c3a2-4c64-a5fb-f697ab77f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(max_depth=50, n_estimators=1000, n_jobs=-1,\n",
      "                     random_state=1216)\n"
     ]
    }
   ],
   "source": [
    "print(gridExtraTrees.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "23083fcc-aae9-4436-87ab-ccd9a47a44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_extra_trees = gridExtraTrees.best_estimator_\n",
    "best_extra_trees.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fcf2788-ccff-4871-8a82-fd36a1e1829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      7581\n",
      "           1       0.88      0.93      0.91      7640\n",
      "\n",
      "    accuracy                           0.90     15221\n",
      "   macro avg       0.91      0.90      0.90     15221\n",
      "weighted avg       0.91      0.90      0.90     15221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_xtr = best_extra_trees.predict(X_test)\n",
    "print(classification_report(y_test, teste_xtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79596381-0149-494e-a9be-83638bdc788b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faf09e33-e57f-4f4f-bdee-22d619f0935e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setting the Classifier\n",
    "rand_forest = RandomForestClassifier(criterion='gini',\n",
    "                                 max_leaf_nodes=None,\n",
    "                                 bootstrap=True,\n",
    "                                 oob_score=True,\n",
    "                                 n_jobs = -1)\n",
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e64cf28d-394a-4fee-873f-ff175d6767a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid search parameters\n",
    "n_estimators = np.array([1000,2000])\n",
    "max_depth = np.array([50,None])\n",
    "values_grid_forest = {'n_estimators': n_estimators, 'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48ffdcd3-85aa-4b14-9d8e-50e5e2d7fc48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 1/2] END ...max_depth=50, n_estimators=1000;, score=0.778 total time=  29.1s\n",
      "[CV 2/2] END ...max_depth=50, n_estimators=1000;, score=0.782 total time=  27.0s\n",
      "[CV 1/2] END ...max_depth=50, n_estimators=2000;, score=0.778 total time=  51.7s\n",
      "[CV 2/2] END ...max_depth=50, n_estimators=2000;, score=0.781 total time=  50.3s\n",
      "[CV 1/2] END .max_depth=None, n_estimators=1000;, score=0.780 total time=  24.7s\n",
      "[CV 2/2] END .max_depth=None, n_estimators=1000;, score=0.781 total time=  25.1s\n",
      "[CV 1/2] END .max_depth=None, n_estimators=2000;, score=0.779 total time=  49.8s\n",
      "[CV 2/2] END .max_depth=None, n_estimators=2000;, score=0.780 total time=  52.9s\n"
     ]
    }
   ],
   "source": [
    "#Using grid search to find the best values\n",
    "gridForest = GridSearchCV(estimator = rand_forest,\n",
    "                                param_grid = values_grid_forest,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1)\n",
    "gridForest.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62361cad-3e4d-4312-835d-1b96e0243bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.539212</td>\n",
       "      <td>0.205972</td>\n",
       "      <td>2.415994</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 1000}</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>0.781208</td>\n",
       "      <td>0.780496</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.888707</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>5.553616</td>\n",
       "      <td>0.619371</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 2000}</td>\n",
       "      <td>0.779494</td>\n",
       "      <td>0.780432</td>\n",
       "      <td>0.779963</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.602889</td>\n",
       "      <td>1.002855</td>\n",
       "      <td>2.541676</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 1000}</td>\n",
       "      <td>0.777781</td>\n",
       "      <td>0.781854</td>\n",
       "      <td>0.779818</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.237143</td>\n",
       "      <td>0.739148</td>\n",
       "      <td>4.889072</td>\n",
       "      <td>0.031913</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 2000}</td>\n",
       "      <td>0.778428</td>\n",
       "      <td>0.780981</td>\n",
       "      <td>0.779705</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2      22.539212      0.205972         2.415994        0.009011   \n",
       "3      45.888707      0.965653         5.553616        0.619371   \n",
       "0      25.602889      1.002855         2.541676        0.011871   \n",
       "1      46.237143      0.739148         4.889072        0.031913   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "2            None               1000   \n",
       "3            None               2000   \n",
       "0              50               1000   \n",
       "1              50               2000   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "2  {'max_depth': None, 'n_estimators': 1000}           0.779785   \n",
       "3  {'max_depth': None, 'n_estimators': 2000}           0.779494   \n",
       "0    {'max_depth': 50, 'n_estimators': 1000}           0.777781   \n",
       "1    {'max_depth': 50, 'n_estimators': 2000}           0.778428   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "2           0.781208         0.780496        0.000711                1  \n",
       "3           0.780432         0.779963        0.000469                2  \n",
       "0           0.781854         0.779818        0.002036                3  \n",
       "1           0.780981         0.779705        0.001277                4  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_results = pd.DataFrame(gridForest.cv_results_)\n",
    "forest_results.sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75d0bd03-d230-4658-8afe-dae70d5c9780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridForest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "890560c4-7b9e-4c21-9fe7-303a419482b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_forest = gridForest.best_estimator_\n",
    "best_forest.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61b53d08-dd33-4497-943a-6a5be56c404d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      7680\n",
      "           1       0.89      0.93      0.91      7790\n",
      "\n",
      "    accuracy                           0.91     15470\n",
      "   macro avg       0.91      0.91      0.91     15470\n",
      "weighted avg       0.91      0.91      0.91     15470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_rnd = best_forest.predict(X_test)\n",
    "print(classification_report(y_test, teste_rnd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c34031-44fa-47fd-a6d1-71688d41926a",
   "metadata": {},
   "source": [
    "#### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88028554-e1b0-4cdc-a791-a39884a3c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the classifier\n",
    "ada_boost = AdaBoostClassifier(random_state = 1216)\n",
    "X, y = df_splitter(datasets['smoted-'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8048bb79-23c8-4bf2-b584-53abda16624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.array([200,300,600])\n",
    "learning_rate = np.array([1.0,1.5])\n",
    "values_grid_ada = {'n_estimators': n_estimators, 'learning_rate': learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f362d7-44d0-43be-bb8b-32bd49c77585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=200;, score=0.814 total time=   6.9s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=200;, score=0.815 total time=   7.0s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=300;, score=0.817 total time=  10.4s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=300;, score=0.817 total time=  10.4s\n",
      "[CV 1/2] END learning_rate=1.0, n_estimators=600;, score=0.817 total time=  20.7s\n",
      "[CV 2/2] END learning_rate=1.0, n_estimators=600;, score=0.818 total time=  20.3s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=200;, score=0.817 total time=   6.6s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=200;, score=0.818 total time=   6.5s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=300;, score=0.817 total time=  10.3s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=300;, score=0.817 total time=   9.8s\n",
      "[CV 1/2] END learning_rate=1.5, n_estimators=600;, score=0.817 total time=  19.3s\n",
      "[CV 2/2] END learning_rate=1.5, n_estimators=600;, score=0.817 total time=  19.7s\n"
     ]
    }
   ],
   "source": [
    "#Using grid search to find the best values\n",
    "gridAda = GridSearchCV(estimator = ada_boost,\n",
    "                                param_grid = values_grid_ada,\n",
    "                                cv = 2, verbose = 3,\n",
    "                                scoring='accuracy',\n",
    "                                pre_dispatch=-1)\n",
    "gridAda.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ea4ae3-2d26-413c-aaa6-7b06094ae503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.329516</td>\n",
       "      <td>0.301499</td>\n",
       "      <td>4.286994</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 600}</td>\n",
       "      <td>0.817489</td>\n",
       "      <td>0.818041</td>\n",
       "      <td>0.817765</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.216989</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>1.472008</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>1.5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 200}</td>\n",
       "      <td>0.817390</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.817470</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.347001</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>2.175508</td>\n",
       "      <td>0.032493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>0.817259</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.817322</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.993500</td>\n",
       "      <td>0.098484</td>\n",
       "      <td>2.161003</td>\n",
       "      <td>0.114998</td>\n",
       "      <td>1.5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 300}</td>\n",
       "      <td>0.817423</td>\n",
       "      <td>0.817089</td>\n",
       "      <td>0.817256</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.428005</td>\n",
       "      <td>0.227010</td>\n",
       "      <td>4.166493</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>1.5</td>\n",
       "      <td>600</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 600}</td>\n",
       "      <td>0.816799</td>\n",
       "      <td>0.817122</td>\n",
       "      <td>0.816960</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.543011</td>\n",
       "      <td>0.100033</td>\n",
       "      <td>1.508509</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>0.814724</td>\n",
       "      <td>0.814530</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2      16.329516      0.301499         4.286994        0.105011   \n",
       "3       5.216989      0.044990         1.472008        0.012014   \n",
       "1       8.347001      0.014000         2.175508        0.032493   \n",
       "4       7.993500      0.098484         2.161003        0.114998   \n",
       "5      15.428005      0.227010         4.166493        0.011508   \n",
       "0       5.543011      0.100033         1.508509        0.005508   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "2                 1.0                600   \n",
       "3                 1.5                200   \n",
       "1                 1.0                300   \n",
       "4                 1.5                300   \n",
       "5                 1.5                600   \n",
       "0                 1.0                200   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "2  {'learning_rate': 1.0, 'n_estimators': 600}           0.817489   \n",
       "3  {'learning_rate': 1.5, 'n_estimators': 200}           0.817390   \n",
       "1  {'learning_rate': 1.0, 'n_estimators': 300}           0.817259   \n",
       "4  {'learning_rate': 1.5, 'n_estimators': 300}           0.817423   \n",
       "5  {'learning_rate': 1.5, 'n_estimators': 600}           0.816799   \n",
       "0  {'learning_rate': 1.0, 'n_estimators': 200}           0.814335   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "2           0.818041         0.817765        0.000276                1  \n",
       "3           0.817549         0.817470        0.000079                2  \n",
       "1           0.817384         0.817322        0.000063                3  \n",
       "4           0.817089         0.817256        0.000167                4  \n",
       "5           0.817122         0.816960        0.000161                5  \n",
       "0           0.814724         0.814530        0.000194                6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results = pd.DataFrame(gridAda.cv_results_)\n",
    "ada_results.sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991f911c-dee1-4566-bae3-3bef73d2c8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=600, random_state=1216)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=600, random_state=1216)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=600, random_state=1216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridAda.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1325812e-1194-4a8e-8f93-d63ba27a1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ada = gridAda.best_estimator_\n",
    "best_ada.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68bb6860-b8e4-4176-a602-9e86c20212ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84      7581\n",
      "           1       0.93      0.68      0.79      7640\n",
      "\n",
      "    accuracy                           0.82     15221\n",
      "   macro avg       0.84      0.82      0.81     15221\n",
      "weighted avg       0.84      0.82      0.81     15221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_ada = best_ada.predict(X_test)\n",
    "print(classification_report(y_test, teste_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb456236-a450-476a-b856-4ec42b7cda45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "779d5e01-3617-4db0-9555-14766b30562c",
   "metadata": {},
   "source": [
    "### Final processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721aac3b-af19-4845-888f-71b897c078db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83015a4-1415-4d69-879c-3b2938fbca97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e64bc-c0a5-4fa3-bff3-da9bb5dbe76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb57534b-c44e-4268-a448-67a72448e2a1",
   "metadata": {},
   "source": [
    "Extra tress cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a2bb09b-eb3a-4b4f-ae7d-962f5f807241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.88898013 0.89275743 0.8845459  0.88879763 0.88764783 0.88452694\n",
      " 0.89273982 0.88764783 0.89388962 0.88206307]\n",
      "\n",
      "Mean: 0.8883596208366955\n",
      "Standard deviation: 0.003736017853944822\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled-'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "extrees = ExtraTreesClassifier(max_depth=50, n_estimators=1000, n_jobs=-1)\n",
    "extrees_test = cross_val_score(extrees,X_train,y_train, n_jobs=-1, cv=10, scoring='accuracy')\n",
    "display_scores(extrees_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd4e5b-b509-4da9-8376-3f4433782fae",
   "metadata": {},
   "source": [
    "Random forest Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a46297e6-f8fc-4e21-8974-0ffc7b021e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.88768584 0.89140271 0.88623142 0.89091791 0.88994829 0.89091791\n",
      " 0.88766769 0.89348634 0.89073865 0.90415387]\n",
      "\n",
      "Mean: 0.8913150621614289\n",
      "Standard deviation: 0.004736992309822998\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rand_forest = RandomForestClassifier(criterion='gini',max_leaf_nodes=None,bootstrap=True,oob_score=True,n_estimators=1000,n_jobs = -1)\n",
    "rand_forest_test = cross_val_score(rand_forest,X_train,y_train, n_jobs=-1, cv=10, scoring='accuracy')\n",
    "display_scores(rand_forest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4ee2e5a-e057-46fb-ba03-8dffffe7ce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.71710362 0.7113608  0.72172285 0.71756774 0.72056437]\n",
      "\n",
      "Mean: 0.7176638734607088\n",
      "Standard deviation: 0.003603886423134835\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['outliers_removed'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "extrees = ExtraTreesClassifier(max_depth=50, n_estimators=1000, n_jobs=-1)\n",
    "extrees_test = cross_val_score(extrees,X_train,y_train, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "display_scores(extrees_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47131747-c758-446d-9909-4cdb6f4d8bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.75408426 0.74867952 0.75052205 0.75039921 0.75125906]\n",
      "\n",
      "Mean: 0.7509888220120378\n",
      "Standard deviation: 0.0017636989161820362\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['one_hot_encoded_rescaled'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rand_forest = RandomForestClassifier(criterion='gini',max_leaf_nodes=None,bootstrap=True,oob_score=True,n_estimators=1000,n_jobs = -1)\n",
    "rand_forest_test = cross_val_score(rand_forest,X_train,y_train, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "display_scores(rand_forest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a13e570-06f0-4c95-846e-2837eb7c18fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      7681\n",
      "           1       0.92      0.96      0.94      2496\n",
      "\n",
      "    accuracy                           0.97     10177\n",
      "   macro avg       0.96      0.97      0.96     10177\n",
      "weighted avg       0.97      0.97      0.97     10177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['one_hot_encoded_rescaled'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "teste = best_forest.predict(X_test)\n",
    "print(classification_report(y_test, teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ea4883b-b368-4235-907c-fdb8c326481b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7679\n",
      "           1       0.89      0.73      0.80      2498\n",
      "\n",
      "    accuracy                           0.91     10177\n",
      "   macro avg       0.90      0.85      0.87     10177\n",
      "weighted avg       0.91      0.91      0.91     10177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['one_hot_encoded_rescaled'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "teste = best_extra_trees.predict(X_test)\n",
    "print(classification_report(y_test, teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933416b3-bca2-4405-9510-dc63bdf54650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8ad4c-8f84-4488-8082-5efc96052c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95caa48-a7fd-449f-b8a5-a969ba403871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a93dbf-c7a4-4d4b-982a-261b46e63290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b690a5-9334-4c26-a167-ba1cd3ab1bae",
   "metadata": {},
   "source": [
    "# AGAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af6ffb-8f82-4687-a7dc-571f002d87fb",
   "metadata": {},
   "source": [
    "### 4. Further cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98768f-bb35-42df-951f-2b29f921a739",
   "metadata": {},
   "source": [
    "Further cross validation to verify possible overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d051e05c-dec0-4b9f-a593-2b313306778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.90147783 0.90114943 0.8955665  0.90111695 0.89191853 0.90078844\n",
      " 0.90078844 0.90013141 0.89586071 0.90013141 0.89323259 0.89388962\n",
      " 0.90243101 0.88863338 0.88567674 0.88764783 0.9021025  0.89520368\n",
      " 0.8978318  0.89684625]\n",
      "\n",
      "Mean: 0.8966212517450678\n",
      "Standard deviation: 0.004989290002455759\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled-'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "extrees = ExtraTreesClassifier(max_depth=50, n_estimators=1000, n_jobs=-1)\n",
    "extrees_test = cross_val_score(extrees,X_train,y_train, n_jobs=-1, cv=20, scoring='accuracy')\n",
    "display_scores(extrees_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c242f4c-9e66-4ef5-924f-6aced3522843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.90012928 0.90885585 0.89689722 0.89172592 0.90368455 0.89301875\n",
      " 0.89301875 0.89625081 0.89948287 0.90917906 0.89625081 0.89431157\n",
      " 0.89883646 0.89819005 0.89528119 0.89463478 0.88587132 0.89848044\n",
      " 0.90365341 0.89848044]\n",
      "\n",
      "Mean: 0.8978116755916721\n",
      "Standard deviation: 0.005431703718543959\n"
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rand_forest = RandomForestClassifier(criterion='gini',max_leaf_nodes=None,bootstrap=True,oob_score=True,n_estimators=1000,n_jobs = -1)\n",
    "rand_forest_test = cross_val_score(rand_forest,X_train,y_train, n_jobs=-1, cv=20, scoring='accuracy')\n",
    "display_scores(rand_forest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1dbaa452-e53e-4e54-8a8e-178511ac1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 0. 1. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m X, y \u001b[38;5;241m=\u001b[39m df_splitter(datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moversampled+\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m teste_rnd \u001b[38;5;241m=\u001b[39m \u001b[43mbest_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, teste_rnd))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:832\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 832\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:874\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    872\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 874\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    877\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 605\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 0. 1. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "teste_rnd = best_forest.predict(y_test)\n",
    "print(classification_report(y_test, teste_rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569a8aa-39b7-409a-99ad-7dd66bcb5171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aad103-d27f-4325-8dfc-a853713774bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b43ba0e2-200c-44e7-85c4-b4b6da6fc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sets = ['one_hot_encoded','outliers_removed','one_hot_encoded_rescaled','oversampled+','oversampled-','smoted+','smoted-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8aad2d0-9169-4231-815f-0cbe6cb4b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores, dataset):\n",
    "    print(\"\\nMean score:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b02a682-b5d2-41bb-8864-2c28296d09e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91     38673\n",
      "           1       0.93      0.41      0.57     12209\n",
      "\n",
      "    accuracy                           0.85     50882\n",
      "   macro avg       0.89      0.70      0.74     50882\n",
      "weighted avg       0.86      0.85      0.83     50882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91     38052\n",
      "           1       0.93      0.40      0.56     12009\n",
      "\n",
      "    accuracy                           0.85     50061\n",
      "   macro avg       0.89      0.70      0.74     50061\n",
      "weighted avg       0.86      0.85      0.83     50061\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     38673\n",
      "           1       0.93      0.97      0.95     12209\n",
      "\n",
      "    accuracy                           0.97     50882\n",
      "   macro avg       0.96      0.97      0.97     50882\n",
      "weighted avg       0.98      0.97      0.98     50882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     38673\n",
      "           1       0.98      0.99      0.98     38673\n",
      "\n",
      "    accuracy                           0.98     77346\n",
      "   macro avg       0.98      0.98      0.98     77346\n",
      "weighted avg       0.98      0.98      0.98     77346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.77     38052\n",
      "           1       0.98      0.40      0.57     38052\n",
      "\n",
      "    accuracy                           0.70     76104\n",
      "   macro avg       0.80      0.70      0.67     76104\n",
      "weighted avg       0.80      0.70      0.67     76104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81     38673\n",
      "           1       0.96      0.56      0.71     38673\n",
      "\n",
      "    accuracy                           0.77     77346\n",
      "   macro avg       0.83      0.77      0.76     77346\n",
      "weighted avg       0.83      0.77      0.76     77346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69     38052\n",
      "           1       0.94      0.13      0.23     38052\n",
      "\n",
      "    accuracy                           0.56     76104\n",
      "   macro avg       0.73      0.56      0.46     76104\n",
      "weighted avg       0.73      0.56      0.46     76104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in final_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    teste_rnd = best_forest.predict(X)\n",
    "    print(classification_report(y, teste_rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c1f63b8-15b6-433b-a997-4365060cc19f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     38673\n",
      "           1       0.92      0.96      0.94     12209\n",
      "\n",
      "    accuracy                           0.97     50882\n",
      "   macro avg       0.95      0.97      0.96     50882\n",
      "weighted avg       0.97      0.97      0.97     50882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     38052\n",
      "           1       0.92      0.97      0.95     12009\n",
      "\n",
      "    accuracy                           0.97     50061\n",
      "   macro avg       0.96      0.97      0.96     50061\n",
      "weighted avg       0.97      0.97      0.97     50061\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     38673\n",
      "           1       0.88      0.71      0.78     12209\n",
      "\n",
      "    accuracy                           0.91     50882\n",
      "   macro avg       0.89      0.84      0.86     50882\n",
      "weighted avg       0.90      0.91      0.90     50882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86     38673\n",
      "           1       0.96      0.71      0.82     38673\n",
      "\n",
      "    accuracy                           0.84     77346\n",
      "   macro avg       0.86      0.84      0.84     77346\n",
      "weighted avg       0.86      0.84      0.84     77346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     38052\n",
      "           1       0.98      0.99      0.98     38052\n",
      "\n",
      "    accuracy                           0.98     76104\n",
      "   macro avg       0.98      0.98      0.98     76104\n",
      "weighted avg       0.98      0.98      0.98     76104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.97      0.73     38673\n",
      "           1       0.91      0.32      0.47     38673\n",
      "\n",
      "    accuracy                           0.64     77346\n",
      "   macro avg       0.75      0.64      0.60     77346\n",
      "weighted avg       0.75      0.64      0.60     77346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74     38052\n",
      "           1       0.93      0.36      0.52     38052\n",
      "\n",
      "    accuracy                           0.67     76104\n",
      "   macro avg       0.77      0.67      0.63     76104\n",
      "weighted avg       0.77      0.67      0.63     76104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in final_sets:\n",
    "    X, y = df_splitter(datasets[key])\n",
    "    teste_rnd = best_extra_trees.predict(X)\n",
    "    print(classification_report(y, teste_rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e9507e8-f7d3-4f86-80c5-ef12e98664fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3dfef98f-7d10-40c4-b031-ee3b104e079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7660\n",
      "           1       0.98      0.98      0.98      7810\n",
      "\n",
      "    accuracy                           0.98     15470\n",
      "   macro avg       0.98      0.98      0.98     15470\n",
      "weighted avg       0.98      0.98      0.98     15470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_rnd = best_forest.predict(X_test)\n",
    "print(classification_report(y_test, teste_rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04337eff-b85f-4c6a-8c76-317ea08e93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_curve, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "821fe7dc-9f40-4057-ad9c-f148f1851b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive rate')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresh = roc_curve(y_test, teste_rnd, pos_label=1)\n",
    "plt.plot(fpr, tpr,label='Random Forest')\n",
    "plt.title('RandomForest ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256b9d6-6855-4c97-8357-61fccc883db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404a160-ff70-48dc-8922-afd2caaa159c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16888823-21bc-47aa-b37d-8605c417ed3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0a4444d-9fc9-4863-96cc-f4aa550217bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9816418875242404"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "cm = ConfusionMatrix(best_forest)\n",
    "cm.fit(X_train, y_train)\n",
    "cm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bb73a-a2b1-4460-8e47-dfdf28748d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457730a9-1996-442b-a811-382d55c92450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46a8f1e6-e2a5-4d99-9906-15c63ca7fdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age_Gap', 'Has_Own_House', 'Is_Spouse',\n",
       "       'Reco_Individual_Insurance', 'Reco_Policy_Premium',\n",
       "       'Holding_Policy_Duration', 'Health_Indicator_2', 'Health_Indicator_3',\n",
       "       'Health_Indicator_4', 'Health_Indicator_5', 'City_Group_1',\n",
       "       'City_Group_2', 'City_Group_3', 'City_Group_4', 'Region_Group_1',\n",
       "       'Region_Group_2', 'Region_Group_3', 'Region_Group_4', 'Region_Group_5',\n",
       "       'Region_Group_6', 'Region_Group_7', 'Region_Group_8', 'Region_Group_9',\n",
       "       'Region_Group_10', 'Region_Group_11', 'Region_Group_12',\n",
       "       'Region_Group_13', 'Region_Group_14', 'Region_Group_15',\n",
       "       'Region_Group_16', 'Region_Group_17', 'Region_Group_18',\n",
       "       'Region_Group_19', 'Holding_Policy_Type_1', 'Holding_Policy_Type_2',\n",
       "       'Holding_Policy_Type_3', 'Holding_Policy_Type_4',\n",
       "       'Reco_Policy_Groups_1', 'Reco_Policy_Groups_2', 'Reco_Policy_Groups_3',\n",
       "       'Reco_Policy_Groups_4', 'Response'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['oversampled+'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b279b7db-8653-418a-bad6-46644ec73d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (4,10))\n",
    "sns.heatmap(feature_imp, annot=False, cmap='gist_earth_r').set(title='Correlation Heatmap');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "64aba5e0-8505-422b-82ae-ccc5a090c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\phik\\phik.py:319: RuntimeWarning: invalid value encountered in sqrt\n",
      "  global_correlations = np.sqrt(\n"
     ]
    }
   ],
   "source": [
    "global_correlation, global_labels = X.global_phik(interval_cols=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "474e9ae0-6951-4aea-abe6-4b314f47e750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (2,6))\n",
    "sns.heatmap(global_correlation, xticklabels=[''], yticklabels=global_labels,cmap='gist_earth_r').set(title=r'Global Correlation ($gK$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117efdef-27d0-4969-b8ea-edbeec5f3af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71e7d6-5c04-4d03-a2b4-05a8b21d5fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920feed2-cc86-4d4a-8e91-1ce8eb6e684a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b502f627-aab8-40ca-a71a-4b390349b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(best_forest.feature_importances_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b4d81bd-b3d7-405e-b96c-196b675d8cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.180732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Gap</th>\n",
       "      <td>0.031301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has_Own_House</th>\n",
       "      <td>0.025632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is_Spouse</th>\n",
       "      <td>0.008090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reco_Individual_Insurance</th>\n",
       "      <td>0.006745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "      <td>0.233687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <td>0.081815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health_Indicator_2</th>\n",
       "      <td>0.025126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health_Indicator_3</th>\n",
       "      <td>0.019664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health_Indicator_4</th>\n",
       "      <td>0.016751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health_Indicator_5</th>\n",
       "      <td>0.012445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Group_1</th>\n",
       "      <td>0.014523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Group_2</th>\n",
       "      <td>0.019601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Group_3</th>\n",
       "      <td>0.016110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Group_4</th>\n",
       "      <td>0.019007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_1</th>\n",
       "      <td>0.010216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_2</th>\n",
       "      <td>0.010328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_3</th>\n",
       "      <td>0.010226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_4</th>\n",
       "      <td>0.010047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_5</th>\n",
       "      <td>0.010271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_6</th>\n",
       "      <td>0.010755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_7</th>\n",
       "      <td>0.010397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_8</th>\n",
       "      <td>0.010512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_9</th>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_10</th>\n",
       "      <td>0.009427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_11</th>\n",
       "      <td>0.009231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_12</th>\n",
       "      <td>0.010680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_13</th>\n",
       "      <td>0.010471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_14</th>\n",
       "      <td>0.010657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_15</th>\n",
       "      <td>0.010868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_16</th>\n",
       "      <td>0.010241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_17</th>\n",
       "      <td>0.010759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_18</th>\n",
       "      <td>0.010098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Group_19</th>\n",
       "      <td>0.009363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holding_Policy_Type_1</th>\n",
       "      <td>0.012143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holding_Policy_Type_2</th>\n",
       "      <td>0.011223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holding_Policy_Type_3</th>\n",
       "      <td>0.014670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holding_Policy_Type_4</th>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reco_Policy_Groups_1</th>\n",
       "      <td>0.011608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reco_Policy_Groups_2</th>\n",
       "      <td>0.009581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reco_Policy_Groups_3</th>\n",
       "      <td>0.013388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reco_Policy_Groups_4</th>\n",
       "      <td>0.012504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "Age                        0.180732\n",
       "Age_Gap                    0.031301\n",
       "Has_Own_House              0.025632\n",
       "Is_Spouse                  0.008090\n",
       "Reco_Individual_Insurance  0.006745\n",
       "Reco_Policy_Premium        0.233687\n",
       "Holding_Policy_Duration    0.081815\n",
       "Health_Indicator_2         0.025126\n",
       "Health_Indicator_3         0.019664\n",
       "Health_Indicator_4         0.016751\n",
       "Health_Indicator_5         0.012445\n",
       "City_Group_1               0.014523\n",
       "City_Group_2               0.019601\n",
       "City_Group_3               0.016110\n",
       "City_Group_4               0.019007\n",
       "Region_Group_1             0.010216\n",
       "Region_Group_2             0.010328\n",
       "Region_Group_3             0.010226\n",
       "Region_Group_4             0.010047\n",
       "Region_Group_5             0.010271\n",
       "Region_Group_6             0.010755\n",
       "Region_Group_7             0.010397\n",
       "Region_Group_8             0.010512\n",
       "Region_Group_9             0.010380\n",
       "Region_Group_10            0.009427\n",
       "Region_Group_11            0.009231\n",
       "Region_Group_12            0.010680\n",
       "Region_Group_13            0.010471\n",
       "Region_Group_14            0.010657\n",
       "Region_Group_15            0.010868\n",
       "Region_Group_16            0.010241\n",
       "Region_Group_17            0.010759\n",
       "Region_Group_18            0.010098\n",
       "Region_Group_19            0.009363\n",
       "Holding_Policy_Type_1      0.012143\n",
       "Holding_Policy_Type_2      0.011223\n",
       "Holding_Policy_Type_3      0.014670\n",
       "Holding_Policy_Type_4      0.008729\n",
       "Reco_Policy_Groups_1       0.011608\n",
       "Reco_Policy_Groups_2       0.009581\n",
       "Reco_Policy_Groups_3       0.013388\n",
       "Reco_Policy_Groups_4       0.012504"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342589e0-e1f3-4938-8618-04438bf4fb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf868af-376b-470a-9637-6e1f48a56982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6cc70-1861-487f-a600-ef3057d54104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c089f-9394-4923-859f-0ac728477009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce021ce-68ef-47a5-9298-b426df8d5f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b2ec8-95ce-4afb-a52c-a667d996e343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c817e5d8-9b0b-47b8-a05f-24888f072ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_random_forest.joblib']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_forest, \"my_random_forest.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5ebe8-1f85-4210-8f25-55eee0b5c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "loaded_rf = joblib.load(\"my_random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2304cb-1c2d-4458-86b0-1ac4fbe2f523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f8c151d9-4573-410f-8636-d3ccfab677c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./preprocessed_pipeline.pkl']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_forest, './preprocessed_pipeline.pkl', compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "637b0517-d3f6-4812-bc5f-548c15b5e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_preprocessed_pipeline = joblib.load('./preprocessed_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4beaace0-583b-4e30-b650-8b09f29feaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "joblib_file = 'best_forest.joblib'\n",
    "\n",
    "with open(joblib_file, 'wb') as f:\n",
    "    dump(best_forest, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acd7684c-0d06-4bed-a444-56cf12227ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aaa31c26-569c-4e18-b9b3-6f4af3fc8b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_preprocessed_pipeline.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d34f3717-814f-423c-b9e9-e01fe78d2c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9805429864253393"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = df_splitter(datasets['oversampled+'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "cm = ConfusionMatrix(loaded_preprocessed_pipeline)\n",
    "cm.fit(X_train, y_train)\n",
    "cm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18adb30f-9cb8-400a-8b99-e441b97128c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9886d2-6a30-47d4-8c66-f81e51a447fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cff98e9-4f99-4862-b175-559ba0a3a557",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not RandomForestClassifier",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m loaded_forest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(joblib_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_forest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    577\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not RandomForestClassifier"
     ]
    }
   ],
   "source": [
    "# Name of the file\n",
    "\n",
    "loaded_forest = None\n",
    "\n",
    "with open(joblib_file, 'wb') as f:\n",
    "    load(best_forest, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a276d-c065-48da-a1da-d30ee47c02b5",
   "metadata": {},
   "source": [
    "^^  IF it works above delete below VV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
